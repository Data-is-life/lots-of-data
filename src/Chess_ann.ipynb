{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:07:28.522512Z",
     "start_time": "2018-11-01T03:07:28.493491Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import theano\n",
    "import pickle\n",
    "\n",
    "from pandas import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals.joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:11.454731Z",
     "start_time": "2018-11-01T02:47:11.416053Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_for_model.csv')\n",
    "# df['start_time'] = df['start_time']//1000\n",
    "df = df[df['result'] != 0.5]\n",
    "numeric_predictors = ['color', 'diff', 'game_time', 'start_time', 'weekday']\n",
    "X = df[numeric_predictors]\n",
    "y = np.array(df['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:11.568502Z",
     "start_time": "2018-11-01T02:47:11.456507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2076, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:11.596541Z",
     "start_time": "2018-11-01T02:47:11.570851Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2076,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:11.619974Z",
     "start_time": "2018-11-01T02:47:11.598748Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.15, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:11.865793Z",
     "start_time": "2018-11-01T02:47:11.842030Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X[:1876]\n",
    "y_train = y[:1876]\n",
    "X_test = X[1876:]\n",
    "y_test = y[1876:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:12.364517Z",
     "start_time": "2018-11-01T02:47:12.339942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:12.879388Z",
     "start_time": "2018-11-01T02:47:12.854841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:13.502601Z",
     "start_time": "2018-11-01T02:47:13.480007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:14.079729Z",
     "start_time": "2018-11-01T02:47:14.025615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guess/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/guess/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/guess/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/guess/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "std_sclr = StandardScaler()\n",
    "X_train = std_sclr.fit_transform(X_train)\n",
    "X_test = std_sclr.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:14.625804Z",
     "start_time": "2018-11-01T02:47:14.590549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.49989999,  76.59092228, 131.5902732 ,   4.6553088 ,\n",
       "         1.96720614])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_sclr.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:30:46.289837Z",
     "start_time": "2018-11-01T03:30:46.264120Z"
    }
   },
   "outputs": [],
   "source": [
    "def _classifier():\n",
    "    classifier = Sequential()\n",
    "\n",
    "    classifier.add(Dense(units=13, kernel_initializer='uniform',\n",
    "                         activation='relu', input_dim=5))\n",
    "\n",
    "    classifier.add(\n",
    "        Dense(units=83, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "    classifier.add(\n",
    "        Dense(units=13, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "#     classifier.add(\n",
    "#         Dense(units=109, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "#     classifier.add(\n",
    "#         Dense(units=47, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "#     classifier.add(\n",
    "#         Dense(units=11, kernel_initializer='uniform', activation='softmax'))\n",
    "\n",
    "    classifier.add(\n",
    "        Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(\n",
    "        optimizer='nadam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:30:46.998766Z",
     "start_time": "2018-11-01T03:30:46.895007Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = _classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:36:03.807645Z",
     "start_time": "2018-11-01T03:30:47.503827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 1s 556us/step - loss: 0.6932 - binary_accuracy: 0.4936\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 0s 41us/step - loss: 0.6932 - binary_accuracy: 0.5053\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 0s 44us/step - loss: 0.6931 - binary_accuracy: 0.5053\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.6931 - binary_accuracy: 0.5053\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 0s 47us/step - loss: 0.6931 - binary_accuracy: 0.5053\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 0s 47us/step - loss: 0.6931 - binary_accuracy: 0.5053\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.6929 - binary_accuracy: 0.5053\n",
      "Epoch 8/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.6898 - binary_accuracy: 0.5064\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 0s 31us/step - loss: 0.6773 - binary_accuracy: 0.6370\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.6544 - binary_accuracy: 0.6940\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.6274 - binary_accuracy: 0.7084\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.6040 - binary_accuracy: 0.7132\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5881 - binary_accuracy: 0.7047\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.5788 - binary_accuracy: 0.7015\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.5736 - binary_accuracy: 0.7010\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 0s 45us/step - loss: 0.5707 - binary_accuracy: 0.7015\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 0s 33us/step - loss: 0.5686 - binary_accuracy: 0.7020\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 0s 37us/step - loss: 0.5669 - binary_accuracy: 0.6999\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 0s 40us/step - loss: 0.5654 - binary_accuracy: 0.7020\n",
      "Epoch 20/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.5641 - binary_accuracy: 0.6999\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 0s 47us/step - loss: 0.5629 - binary_accuracy: 0.7015\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 0s 34us/step - loss: 0.5619 - binary_accuracy: 0.7058\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 0s 34us/step - loss: 0.5609 - binary_accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 0s 33us/step - loss: 0.5600 - binary_accuracy: 0.7058\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 0s 33us/step - loss: 0.5592 - binary_accuracy: 0.7068\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 0s 44us/step - loss: 0.5584 - binary_accuracy: 0.7063\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 0s 47us/step - loss: 0.5577 - binary_accuracy: 0.7074\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 0s 37us/step - loss: 0.5572 - binary_accuracy: 0.7084\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 0s 33us/step - loss: 0.5567 - binary_accuracy: 0.7090\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 0s 29us/step - loss: 0.5563 - binary_accuracy: 0.7100\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 0s 30us/step - loss: 0.5559 - binary_accuracy: 0.7095\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 0s 45us/step - loss: 0.5556 - binary_accuracy: 0.7090\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 0s 46us/step - loss: 0.5553 - binary_accuracy: 0.7100\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.5550 - binary_accuracy: 0.7090\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 0s 30us/step - loss: 0.5548 - binary_accuracy: 0.7079\n",
      "Epoch 36/100\n",
      "1876/1876 [==============================] - 0s 44us/step - loss: 0.5546 - binary_accuracy: 0.7084\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 0s 40us/step - loss: 0.5544 - binary_accuracy: 0.7084\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 0s 42us/step - loss: 0.5542 - binary_accuracy: 0.7074\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.5541 - binary_accuracy: 0.7074\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 0s 40us/step - loss: 0.5540 - binary_accuracy: 0.7074\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 0s 49us/step - loss: 0.5538 - binary_accuracy: 0.7074\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 0s 32us/step - loss: 0.5537 - binary_accuracy: 0.7068\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5537 - binary_accuracy: 0.7068\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5536 - binary_accuracy: 0.7068\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 0s 29us/step - loss: 0.5535 - binary_accuracy: 0.7068\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 0s 29us/step - loss: 0.5534 - binary_accuracy: 0.7068\n",
      "Epoch 47/100\n",
      "1876/1876 [==============================] - 0s 39us/step - loss: 0.5533 - binary_accuracy: 0.7068\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 0s 46us/step - loss: 0.5532 - binary_accuracy: 0.7068\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 0s 30us/step - loss: 0.5531 - binary_accuracy: 0.7068\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 0s 44us/step - loss: 0.5531 - binary_accuracy: 0.7068\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 0s 49us/step - loss: 0.5530 - binary_accuracy: 0.7068\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 0s 37us/step - loss: 0.5529 - binary_accuracy: 0.7074\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 0s 40us/step - loss: 0.5529 - binary_accuracy: 0.7074\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 0s 47us/step - loss: 0.5528 - binary_accuracy: 0.7074\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 0s 41us/step - loss: 0.5527 - binary_accuracy: 0.7074\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 0s 42us/step - loss: 0.5527 - binary_accuracy: 0.7074\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 0s 49us/step - loss: 0.5526 - binary_accuracy: 0.7079\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 0s 68us/step - loss: 0.5526 - binary_accuracy: 0.7074\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 0s 39us/step - loss: 0.5525 - binary_accuracy: 0.7074\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 0s 41us/step - loss: 0.5524 - binary_accuracy: 0.7074\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 0s 48us/step - loss: 0.5523 - binary_accuracy: 0.7074\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 0s 49us/step - loss: 0.5523 - binary_accuracy: 0.7068\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5522 - binary_accuracy: 0.7068\n",
      "Epoch 64/100\n",
      "1876/1876 [==============================] - 0s 39us/step - loss: 0.5521 - binary_accuracy: 0.7074\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.5521 - binary_accuracy: 0.7074\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 0s 41us/step - loss: 0.5520 - binary_accuracy: 0.7068\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 0s 40us/step - loss: 0.5520 - binary_accuracy: 0.7068\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5519 - binary_accuracy: 0.7068\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 0s 43us/step - loss: 0.5518 - binary_accuracy: 0.7068\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 0s 53us/step - loss: 0.5518 - binary_accuracy: 0.7068\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 0s 57us/step - loss: 0.5517 - binary_accuracy: 0.7068\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 0s 59us/step - loss: 0.5517 - binary_accuracy: 0.7068\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 0s 46us/step - loss: 0.5516 - binary_accuracy: 0.7068\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 0s 54us/step - loss: 0.5516 - binary_accuracy: 0.7074\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 0s 31us/step - loss: 0.5515 - binary_accuracy: 0.7068\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5515 - binary_accuracy: 0.7068\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.5514 - binary_accuracy: 0.7063\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 0s 27us/step - loss: 0.5514 - binary_accuracy: 0.7063\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 0s 51us/step - loss: 0.5513 - binary_accuracy: 0.7063\n",
      "Epoch 80/100\n",
      "1876/1876 [==============================] - 0s 42us/step - loss: 0.5513 - binary_accuracy: 0.7063\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 0s 38us/step - loss: 0.5512 - binary_accuracy: 0.7058\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 0s 43us/step - loss: 0.5512 - binary_accuracy: 0.7068\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 0s 45us/step - loss: 0.5511 - binary_accuracy: 0.7068\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 0s 32us/step - loss: 0.5511 - binary_accuracy: 0.7068\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 0s 28us/step - loss: 0.5510 - binary_accuracy: 0.7068\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 0s 28us/step - loss: 0.5509 - binary_accuracy: 0.7068\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 0s 35us/step - loss: 0.5509 - binary_accuracy: 0.7074\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 0s 29us/step - loss: 0.5508 - binary_accuracy: 0.7074\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 0s 36us/step - loss: 0.5508 - binary_accuracy: 0.7074\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 0s 50us/step - loss: 0.5507 - binary_accuracy: 0.7068\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 0s 50us/step - loss: 0.5507 - binary_accuracy: 0.7074\n",
      "Epoch 92/100\n",
      "1876/1876 [==============================] - 0s 58us/step - loss: 0.5506 - binary_accuracy: 0.7079\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 0s 37us/step - loss: 0.5506 - binary_accuracy: 0.7074\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 0s 50us/step - loss: 0.5506 - binary_accuracy: 0.7079\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 0s 41us/step - loss: 0.5505 - binary_accuracy: 0.7079\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 0s 43us/step - loss: 0.5505 - binary_accuracy: 0.7079\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 0s 45us/step - loss: 0.5504 - binary_accuracy: 0.7079\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 0s 52us/step - loss: 0.5503 - binary_accuracy: 0.7079\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 0s 51us/step - loss: 0.5503 - binary_accuracy: 0.7079\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 0s 46us/step - loss: 0.5502 - binary_accuracy: 0.7079\n",
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 0s 85us/step - loss: 0.5513 - binary_accuracy: 0.7074\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 0s 76us/step - loss: 0.5511 - binary_accuracy: 0.7074\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 0s 61us/step - loss: 0.5509 - binary_accuracy: 0.7074\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 0s 87us/step - loss: 0.5507 - binary_accuracy: 0.7068\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 0s 81us/step - loss: 0.5506 - binary_accuracy: 0.7063\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 0s 62us/step - loss: 0.5504 - binary_accuracy: 0.7058\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 0s 62us/step - loss: 0.5502 - binary_accuracy: 0.7052\n",
      "Epoch 8/100\n",
      "1876/1876 [==============================] - 0s 84us/step - loss: 0.5501 - binary_accuracy: 0.7052\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 0s 105us/step - loss: 0.5499 - binary_accuracy: 0.7058\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 0s 72us/step - loss: 0.5498 - binary_accuracy: 0.7052\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 0s 58us/step - loss: 0.5496 - binary_accuracy: 0.7052\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 0s 79us/step - loss: 0.5495 - binary_accuracy: 0.7052\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 0s 91us/step - loss: 0.5494 - binary_accuracy: 0.7068\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 0s 73us/step - loss: 0.5493 - binary_accuracy: 0.7068\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 0s 63us/step - loss: 0.5492 - binary_accuracy: 0.7068\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 0s 88us/step - loss: 0.5490 - binary_accuracy: 0.7079\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 0s 81us/step - loss: 0.5489 - binary_accuracy: 0.7084\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 0s 65us/step - loss: 0.5488 - binary_accuracy: 0.7068\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 0s 59us/step - loss: 0.5487 - binary_accuracy: 0.7079\n",
      "Epoch 20/100\n",
      "1876/1876 [==============================] - 0s 81us/step - loss: 0.5486 - binary_accuracy: 0.7084\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 0s 79us/step - loss: 0.5485 - binary_accuracy: 0.7084\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 0s 77us/step - loss: 0.5484 - binary_accuracy: 0.7090\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 0s 68us/step - loss: 0.5483 - binary_accuracy: 0.7090\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 0s 71us/step - loss: 0.5483 - binary_accuracy: 0.7084\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 0s 90us/step - loss: 0.5482 - binary_accuracy: 0.7084\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 0s 73us/step - loss: 0.5481 - binary_accuracy: 0.7079\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 0s 84us/step - loss: 0.5480 - binary_accuracy: 0.7079\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 0s 104us/step - loss: 0.5479 - binary_accuracy: 0.7074\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 0s 82us/step - loss: 0.5479 - binary_accuracy: 0.7068\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 0s 82us/step - loss: 0.5478 - binary_accuracy: 0.7063\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 0s 80us/step - loss: 0.5477 - binary_accuracy: 0.7068\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 0s 75us/step - loss: 0.5477 - binary_accuracy: 0.7068\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 0s 85us/step - loss: 0.5476 - binary_accuracy: 0.7084\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 0s 82us/step - loss: 0.5475 - binary_accuracy: 0.7084\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 0s 64us/step - loss: 0.5474 - binary_accuracy: 0.7090\n",
      "Epoch 36/100\n",
      "1876/1876 [==============================] - 0s 86us/step - loss: 0.5474 - binary_accuracy: 0.7090\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 0s 67us/step - loss: 0.5473 - binary_accuracy: 0.7068\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 0s 70us/step - loss: 0.5473 - binary_accuracy: 0.7074\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 0s 83us/step - loss: 0.5472 - binary_accuracy: 0.7068\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 0s 67us/step - loss: 0.5471 - binary_accuracy: 0.7074\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 0s 53us/step - loss: 0.5471 - binary_accuracy: 0.7068\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 0s 97us/step - loss: 0.5470 - binary_accuracy: 0.7063\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 0s 65us/step - loss: 0.5470 - binary_accuracy: 0.7063\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 0s 63us/step - loss: 0.5469 - binary_accuracy: 0.7074\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 0s 83us/step - loss: 0.5469 - binary_accuracy: 0.7074\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 0s 80us/step - loss: 0.5468 - binary_accuracy: 0.7079\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 0s 72us/step - loss: 0.5467 - binary_accuracy: 0.7084\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 0s 81us/step - loss: 0.5467 - binary_accuracy: 0.7084\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 0s 72us/step - loss: 0.5466 - binary_accuracy: 0.7079\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 0s 72us/step - loss: 0.5466 - binary_accuracy: 0.7079\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 0s 82us/step - loss: 0.5465 - binary_accuracy: 0.7079\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 0s 74us/step - loss: 0.5465 - binary_accuracy: 0.7090\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 0s 63us/step - loss: 0.5464 - binary_accuracy: 0.7084\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 0s 87us/step - loss: 0.5464 - binary_accuracy: 0.7079\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 0s 70us/step - loss: 0.5463 - binary_accuracy: 0.7084\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 0s 50us/step - loss: 0.5463 - binary_accuracy: 0.7095\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 0s 78us/step - loss: 0.5462 - binary_accuracy: 0.7084\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 0s 76us/step - loss: 0.5462 - binary_accuracy: 0.7090\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 0s 66us/step - loss: 0.5461 - binary_accuracy: 0.7095\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 0s 60us/step - loss: 0.5461 - binary_accuracy: 0.7111\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 0s 85us/step - loss: 0.5460 - binary_accuracy: 0.7106\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 0s 85us/step - loss: 0.5460 - binary_accuracy: 0.7100\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 0s 64us/step - loss: 0.5459 - binary_accuracy: 0.7106\n",
      "Epoch 64/100\n",
      "1876/1876 [==============================] - 0s 83us/step - loss: 0.5459 - binary_accuracy: 0.7100\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 0s 78us/step - loss: 0.5458 - binary_accuracy: 0.7090\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 0s 75us/step - loss: 0.5458 - binary_accuracy: 0.7095\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 0s 65us/step - loss: 0.5457 - binary_accuracy: 0.7095\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 0s 67us/step - loss: 0.5457 - binary_accuracy: 0.7100\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 0s 67us/step - loss: 0.5456 - binary_accuracy: 0.7100\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 0s 75us/step - loss: 0.5456 - binary_accuracy: 0.7100\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 0s 62us/step - loss: 0.5455 - binary_accuracy: 0.7100\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 0s 59us/step - loss: 0.5455 - binary_accuracy: 0.7100\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 0s 65us/step - loss: 0.5454 - binary_accuracy: 0.7106\n",
      "Epoch 74/100\n",
      "1876/1876 [==============================] - 0s 69us/step - loss: 0.5454 - binary_accuracy: 0.7106\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 0s 61us/step - loss: 0.5453 - binary_accuracy: 0.7100\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 0s 68us/step - loss: 0.5453 - binary_accuracy: 0.7100\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 0s 68us/step - loss: 0.5452 - binary_accuracy: 0.7100\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 0s 64us/step - loss: 0.5452 - binary_accuracy: 0.7106\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 0s 65us/step - loss: 0.5451 - binary_accuracy: 0.7100\n",
      "Epoch 80/100\n",
      "1876/1876 [==============================] - 0s 86us/step - loss: 0.5451 - binary_accuracy: 0.7100\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 0s 63us/step - loss: 0.5450 - binary_accuracy: 0.7100\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 0s 87us/step - loss: 0.5450 - binary_accuracy: 0.7100\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 0s 58us/step - loss: 0.5449 - binary_accuracy: 0.7100\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 0s 57us/step - loss: 0.5449 - binary_accuracy: 0.7100\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 0s 51us/step - loss: 0.5448 - binary_accuracy: 0.7100\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 0s 52us/step - loss: 0.5448 - binary_accuracy: 0.7090\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 0s 97us/step - loss: 0.5447 - binary_accuracy: 0.7084\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 0s 74us/step - loss: 0.5447 - binary_accuracy: 0.7084\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 0s 59us/step - loss: 0.5446 - binary_accuracy: 0.7084\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 0s 69us/step - loss: 0.5445 - binary_accuracy: 0.7090\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 0s 106us/step - loss: 0.5445 - binary_accuracy: 0.7090\n",
      "Epoch 92/100\n",
      "1876/1876 [==============================] - 0s 80us/step - loss: 0.5444 - binary_accuracy: 0.7100\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 0s 59us/step - loss: 0.5444 - binary_accuracy: 0.7100\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 0s 93us/step - loss: 0.5443 - binary_accuracy: 0.7095\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 0s 70us/step - loss: 0.5442 - binary_accuracy: 0.7095\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 0s 58us/step - loss: 0.5442 - binary_accuracy: 0.7095\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 0s 98us/step - loss: 0.5441 - binary_accuracy: 0.7106\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 0s 72us/step - loss: 0.5440 - binary_accuracy: 0.7116\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 0s 70us/step - loss: 0.5440 - binary_accuracy: 0.7111\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 0s 85us/step - loss: 0.5439 - binary_accuracy: 0.7116\n",
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 0s 130us/step - loss: 0.5461 - binary_accuracy: 0.7111\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 0s 144us/step - loss: 0.5461 - binary_accuracy: 0.7100\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 0s 140us/step - loss: 0.5457 - binary_accuracy: 0.7095\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 0s 132us/step - loss: 0.5454 - binary_accuracy: 0.7079\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 0s 154us/step - loss: 0.5450 - binary_accuracy: 0.7074\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5447 - binary_accuracy: 0.7106\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 0s 126us/step - loss: 0.5444 - binary_accuracy: 0.7090\n",
      "Epoch 8/100\n",
      "1876/1876 [==============================] - 0s 178us/step - loss: 0.5441 - binary_accuracy: 0.7084\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 0s 133us/step - loss: 0.5439 - binary_accuracy: 0.7084\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5436 - binary_accuracy: 0.7084\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 0s 129us/step - loss: 0.5434 - binary_accuracy: 0.7090\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 0s 129us/step - loss: 0.5432 - binary_accuracy: 0.7095\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5429 - binary_accuracy: 0.7100\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 0s 120us/step - loss: 0.5427 - binary_accuracy: 0.7111\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 0s 109us/step - loss: 0.5425 - binary_accuracy: 0.7100\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 0s 104us/step - loss: 0.5423 - binary_accuracy: 0.7090\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 0s 115us/step - loss: 0.5421 - binary_accuracy: 0.7095\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 0s 126us/step - loss: 0.5420 - binary_accuracy: 0.7111\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5418 - binary_accuracy: 0.7122\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5416 - binary_accuracy: 0.7122\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 0s 108us/step - loss: 0.5414 - binary_accuracy: 0.7127\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5412 - binary_accuracy: 0.7122\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5410 - binary_accuracy: 0.7148\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 0s 117us/step - loss: 0.5408 - binary_accuracy: 0.7138\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5407 - binary_accuracy: 0.7154\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 0s 107us/step - loss: 0.5405 - binary_accuracy: 0.7148\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5404 - binary_accuracy: 0.7164\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5402 - binary_accuracy: 0.7170\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5401 - binary_accuracy: 0.7191\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 0s 123us/step - loss: 0.5400 - binary_accuracy: 0.7186\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5398 - binary_accuracy: 0.7180\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 0s 124us/step - loss: 0.5397 - binary_accuracy: 0.7180\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 0s 134us/step - loss: 0.5396 - binary_accuracy: 0.7191\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 0s 120us/step - loss: 0.5395 - binary_accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5394 - binary_accuracy: 0.7196\n",
      "Epoch 36/100\n",
      "1876/1876 [==============================] - 0s 110us/step - loss: 0.5392 - binary_accuracy: 0.7186\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5391 - binary_accuracy: 0.7180\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5390 - binary_accuracy: 0.7186\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 0s 105us/step - loss: 0.5388 - binary_accuracy: 0.7191\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 0s 107us/step - loss: 0.5387 - binary_accuracy: 0.7186\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 0s 114us/step - loss: 0.5386 - binary_accuracy: 0.7186\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5385 - binary_accuracy: 0.7196\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 0s 119us/step - loss: 0.5383 - binary_accuracy: 0.7201\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 0s 112us/step - loss: 0.5382 - binary_accuracy: 0.7201\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5381 - binary_accuracy: 0.7191\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 0s 116us/step - loss: 0.5380 - binary_accuracy: 0.7186\n",
      "Epoch 47/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5378 - binary_accuracy: 0.7170\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 0s 123us/step - loss: 0.5377 - binary_accuracy: 0.7159\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 0s 126us/step - loss: 0.5376 - binary_accuracy: 0.7170\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 0s 107us/step - loss: 0.5375 - binary_accuracy: 0.7180\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 0s 116us/step - loss: 0.5373 - binary_accuracy: 0.7180\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5372 - binary_accuracy: 0.7175\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 0s 110us/step - loss: 0.5371 - binary_accuracy: 0.7180\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 0s 113us/step - loss: 0.5370 - binary_accuracy: 0.7186\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 0s 129us/step - loss: 0.5369 - binary_accuracy: 0.7186\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 0s 106us/step - loss: 0.5367 - binary_accuracy: 0.7196\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 0s 110us/step - loss: 0.5366 - binary_accuracy: 0.7186\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 0s 120us/step - loss: 0.5365 - binary_accuracy: 0.7191\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 0s 129us/step - loss: 0.5364 - binary_accuracy: 0.7180\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 0s 127us/step - loss: 0.5363 - binary_accuracy: 0.7180\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 0s 116us/step - loss: 0.5362 - binary_accuracy: 0.7186\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 0s 127us/step - loss: 0.5361 - binary_accuracy: 0.7175\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 0s 164us/step - loss: 0.5360 - binary_accuracy: 0.7164\n",
      "Epoch 64/100\n",
      "1876/1876 [==============================] - 0s 157us/step - loss: 0.5359 - binary_accuracy: 0.7164\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 0s 163us/step - loss: 0.5358 - binary_accuracy: 0.7170\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 0s 147us/step - loss: 0.5356 - binary_accuracy: 0.7170\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 0s 144us/step - loss: 0.5355 - binary_accuracy: 0.7175\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5353 - binary_accuracy: 0.7175\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 0s 114us/step - loss: 0.5352 - binary_accuracy: 0.7180\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 0s 110us/step - loss: 0.5351 - binary_accuracy: 0.7180\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 0s 122us/step - loss: 0.5349 - binary_accuracy: 0.7175\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 0s 115us/step - loss: 0.5348 - binary_accuracy: 0.7180\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 0s 125us/step - loss: 0.5347 - binary_accuracy: 0.7175\n",
      "Epoch 74/100\n",
      "1876/1876 [==============================] - 0s 116us/step - loss: 0.5346 - binary_accuracy: 0.7175\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 0s 115us/step - loss: 0.5345 - binary_accuracy: 0.7186\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 0s 108us/step - loss: 0.5343 - binary_accuracy: 0.7180\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 0s 112us/step - loss: 0.5342 - binary_accuracy: 0.7170\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 0s 106us/step - loss: 0.5341 - binary_accuracy: 0.7170\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 0s 118us/step - loss: 0.5340 - binary_accuracy: 0.7164\n",
      "Epoch 80/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5339 - binary_accuracy: 0.7170\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 0s 112us/step - loss: 0.5337 - binary_accuracy: 0.7180\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 0s 174us/step - loss: 0.5336 - binary_accuracy: 0.7164\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 0s 114us/step - loss: 0.5335 - binary_accuracy: 0.7154\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 0s 134us/step - loss: 0.5333 - binary_accuracy: 0.7159\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 0s 142us/step - loss: 0.5332 - binary_accuracy: 0.7154\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 0s 121us/step - loss: 0.5330 - binary_accuracy: 0.7148\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 0s 119us/step - loss: 0.5330 - binary_accuracy: 0.7148\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 0s 153us/step - loss: 0.5328 - binary_accuracy: 0.7164\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 0s 116us/step - loss: 0.5327 - binary_accuracy: 0.7154\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 0s 120us/step - loss: 0.5326 - binary_accuracy: 0.7154\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 0s 127us/step - loss: 0.5325 - binary_accuracy: 0.7154\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 0s 143us/step - loss: 0.5324 - binary_accuracy: 0.7159\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 0s 112us/step - loss: 0.5322 - binary_accuracy: 0.7148\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 0s 111us/step - loss: 0.5321 - binary_accuracy: 0.7148\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 0s 115us/step - loss: 0.5320 - binary_accuracy: 0.7148\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 0s 110us/step - loss: 0.5319 - binary_accuracy: 0.7154\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 0s 109us/step - loss: 0.5318 - binary_accuracy: 0.7148\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 0s 115us/step - loss: 0.5317 - binary_accuracy: 0.7170\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 0s 109us/step - loss: 0.5316 - binary_accuracy: 0.7148\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 0s 105us/step - loss: 0.5315 - binary_accuracy: 0.7148\n",
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5354 - binary_accuracy: 0.7154\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 0s 208us/step - loss: 0.5350 - binary_accuracy: 0.7138\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 0s 257us/step - loss: 0.5345 - binary_accuracy: 0.7148\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 0s 219us/step - loss: 0.5340 - binary_accuracy: 0.7154\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 0s 218us/step - loss: 0.5338 - binary_accuracy: 0.7164\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5335 - binary_accuracy: 0.7164\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 0s 201us/step - loss: 0.5333 - binary_accuracy: 0.7180\n",
      "Epoch 8/100\n",
      "1876/1876 [==============================] - 0s 212us/step - loss: 0.5331 - binary_accuracy: 0.7154\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 0s 209us/step - loss: 0.5328 - binary_accuracy: 0.7154\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5326 - binary_accuracy: 0.7159\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 0s 234us/step - loss: 0.5324 - binary_accuracy: 0.7159\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 0s 239us/step - loss: 0.5322 - binary_accuracy: 0.7159\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5320 - binary_accuracy: 0.7164\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 0s 226us/step - loss: 0.5319 - binary_accuracy: 0.7164\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 0s 228us/step - loss: 0.5318 - binary_accuracy: 0.7175\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5316 - binary_accuracy: 0.7175\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 0s 222us/step - loss: 0.5315 - binary_accuracy: 0.7186\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 0s 254us/step - loss: 0.5314 - binary_accuracy: 0.7175\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 0s 202us/step - loss: 0.5313 - binary_accuracy: 0.7180\n",
      "Epoch 20/100\n",
      "1876/1876 [==============================] - 0s 233us/step - loss: 0.5312 - binary_accuracy: 0.7170\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 0s 213us/step - loss: 0.5311 - binary_accuracy: 0.7164\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 0s 232us/step - loss: 0.5310 - binary_accuracy: 0.7170\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 0s 229us/step - loss: 0.5309 - binary_accuracy: 0.7180\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 0s 220us/step - loss: 0.5308 - binary_accuracy: 0.7180\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 0s 257us/step - loss: 0.5307 - binary_accuracy: 0.7180\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 0s 225us/step - loss: 0.5306 - binary_accuracy: 0.7175\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5305 - binary_accuracy: 0.7170\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 0s 211us/step - loss: 0.5305 - binary_accuracy: 0.7186\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 0s 221us/step - loss: 0.5304 - binary_accuracy: 0.7180\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 0s 229us/step - loss: 0.5303 - binary_accuracy: 0.7175\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 0s 241us/step - loss: 0.5302 - binary_accuracy: 0.7186\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 0s 236us/step - loss: 0.5301 - binary_accuracy: 0.7180\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 0s 215us/step - loss: 0.5301 - binary_accuracy: 0.7175\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 0s 225us/step - loss: 0.5299 - binary_accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 0s 223us/step - loss: 0.5299 - binary_accuracy: 0.7191\n",
      "Epoch 36/100\n",
      "1876/1876 [==============================] - 0s 218us/step - loss: 0.5298 - binary_accuracy: 0.7207\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 0s 214us/step - loss: 0.5297 - binary_accuracy: 0.7201\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 0s 229us/step - loss: 0.5297 - binary_accuracy: 0.7186\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 0s 245us/step - loss: 0.5295 - binary_accuracy: 0.7191\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 0s 224us/step - loss: 0.5295 - binary_accuracy: 0.7201\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 0s 237us/step - loss: 0.5294 - binary_accuracy: 0.7196\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 0s 232us/step - loss: 0.5293 - binary_accuracy: 0.7186\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 0s 214us/step - loss: 0.5292 - binary_accuracy: 0.7186\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 0s 211us/step - loss: 0.5291 - binary_accuracy: 0.7180\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 0s 226us/step - loss: 0.5290 - binary_accuracy: 0.7175\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 0s 228us/step - loss: 0.5289 - binary_accuracy: 0.7180\n",
      "Epoch 47/100\n",
      "1876/1876 [==============================] - 0s 219us/step - loss: 0.5288 - binary_accuracy: 0.7175\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5288 - binary_accuracy: 0.7175\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5287 - binary_accuracy: 0.7175\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 0s 219us/step - loss: 0.5286 - binary_accuracy: 0.7175\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5285 - binary_accuracy: 0.7175\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 0s 227us/step - loss: 0.5284 - binary_accuracy: 0.7175\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5284 - binary_accuracy: 0.7180\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 0s 232us/step - loss: 0.5283 - binary_accuracy: 0.7196\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 0s 222us/step - loss: 0.5281 - binary_accuracy: 0.7201\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 0s 244us/step - loss: 0.5280 - binary_accuracy: 0.7201\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 0s 242us/step - loss: 0.5280 - binary_accuracy: 0.7191\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 0s 226us/step - loss: 0.5279 - binary_accuracy: 0.7207\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 0s 219us/step - loss: 0.5278 - binary_accuracy: 0.7196\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 0s 233us/step - loss: 0.5278 - binary_accuracy: 0.7191\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 0s 245us/step - loss: 0.5276 - binary_accuracy: 0.7196\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 0s 210us/step - loss: 0.5275 - binary_accuracy: 0.7201\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 0s 233us/step - loss: 0.5275 - binary_accuracy: 0.7201\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 0s 218us/step - loss: 0.5274 - binary_accuracy: 0.7207\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 0s 231us/step - loss: 0.5273 - binary_accuracy: 0.7196\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 0s 229us/step - loss: 0.5272 - binary_accuracy: 0.7196\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5271 - binary_accuracy: 0.7186\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 0s 228us/step - loss: 0.5270 - binary_accuracy: 0.7196\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 0s 222us/step - loss: 0.5269 - binary_accuracy: 0.7201\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 0s 213us/step - loss: 0.5268 - binary_accuracy: 0.7186\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 0s 222us/step - loss: 0.5268 - binary_accuracy: 0.7196\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 0s 207us/step - loss: 0.5267 - binary_accuracy: 0.7180\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 0s 210us/step - loss: 0.5266 - binary_accuracy: 0.7180\n",
      "Epoch 74/100\n",
      "1876/1876 [==============================] - 0s 219us/step - loss: 0.5264 - binary_accuracy: 0.7186\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 0s 216us/step - loss: 0.5264 - binary_accuracy: 0.7170\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 0s 218us/step - loss: 0.5263 - binary_accuracy: 0.7180\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 0s 225us/step - loss: 0.5262 - binary_accuracy: 0.7175\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 0s 251us/step - loss: 0.5261 - binary_accuracy: 0.7170\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 0s 257us/step - loss: 0.5260 - binary_accuracy: 0.7180\n",
      "Epoch 80/100\n",
      "1876/1876 [==============================] - 1s 275us/step - loss: 0.5260 - binary_accuracy: 0.7191\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 0s 225us/step - loss: 0.5258 - binary_accuracy: 0.7175\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 0s 260us/step - loss: 0.5258 - binary_accuracy: 0.7186\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 0s 246us/step - loss: 0.5257 - binary_accuracy: 0.7191\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 0s 220us/step - loss: 0.5256 - binary_accuracy: 0.7196\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 0s 254us/step - loss: 0.5254 - binary_accuracy: 0.7196\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 0s 238us/step - loss: 0.5255 - binary_accuracy: 0.7201\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 0s 221us/step - loss: 0.5253 - binary_accuracy: 0.7207\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 0s 238us/step - loss: 0.5252 - binary_accuracy: 0.7191\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 1s 307us/step - loss: 0.5251 - binary_accuracy: 0.7212\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 1s 271us/step - loss: 0.5251 - binary_accuracy: 0.7217\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 0s 232us/step - loss: 0.5250 - binary_accuracy: 0.7217\n",
      "Epoch 92/100\n",
      "1876/1876 [==============================] - 1s 289us/step - loss: 0.5249 - binary_accuracy: 0.7228\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 0s 210us/step - loss: 0.5249 - binary_accuracy: 0.7228\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 1s 270us/step - loss: 0.5247 - binary_accuracy: 0.7233\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 0s 233us/step - loss: 0.5246 - binary_accuracy: 0.7255\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 0s 212us/step - loss: 0.5246 - binary_accuracy: 0.7244\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 0s 257us/step - loss: 0.5244 - binary_accuracy: 0.7260\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 0s 217us/step - loss: 0.5245 - binary_accuracy: 0.7244\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 0s 217us/step - loss: 0.5243 - binary_accuracy: 0.7265\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 0s 222us/step - loss: 0.5242 - binary_accuracy: 0.7271\n",
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 1s 408us/step - loss: 0.5300 - binary_accuracy: 0.7196\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 1s 453us/step - loss: 0.5288 - binary_accuracy: 0.7233\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 1s 428us/step - loss: 0.5280 - binary_accuracy: 0.7249\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 1s 448us/step - loss: 0.5275 - binary_accuracy: 0.7249\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 1s 521us/step - loss: 0.5269 - binary_accuracy: 0.7239\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 1s 455us/step - loss: 0.5268 - binary_accuracy: 0.7228\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 1s 480us/step - loss: 0.5265 - binary_accuracy: 0.7228\n",
      "Epoch 8/100\n",
      "1876/1876 [==============================] - 1s 419us/step - loss: 0.5263 - binary_accuracy: 0.7233\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 1s 520us/step - loss: 0.5259 - binary_accuracy: 0.7233\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 1s 500us/step - loss: 0.5259 - binary_accuracy: 0.7239\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 1s 549us/step - loss: 0.5257 - binary_accuracy: 0.7233\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 1s 479us/step - loss: 0.5255 - binary_accuracy: 0.7265\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 1s 432us/step - loss: 0.5254 - binary_accuracy: 0.7271\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 1s 495us/step - loss: 0.5252 - binary_accuracy: 0.7271\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 1s 470us/step - loss: 0.5251 - binary_accuracy: 0.7271\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 1s 461us/step - loss: 0.5249 - binary_accuracy: 0.7287\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 1s 423us/step - loss: 0.5248 - binary_accuracy: 0.7287\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 1s 460us/step - loss: 0.5246 - binary_accuracy: 0.7271\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 1s 439us/step - loss: 0.5244 - binary_accuracy: 0.7276\n",
      "Epoch 20/100\n",
      "1876/1876 [==============================] - 1s 502us/step - loss: 0.5242 - binary_accuracy: 0.7271\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 1s 498us/step - loss: 0.5241 - binary_accuracy: 0.7265\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 1s 450us/step - loss: 0.5239 - binary_accuracy: 0.7265\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 1s 448us/step - loss: 0.5236 - binary_accuracy: 0.7281\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 1s 458us/step - loss: 0.5234 - binary_accuracy: 0.7276\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 1s 466us/step - loss: 0.5233 - binary_accuracy: 0.7287\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 1s 435us/step - loss: 0.5230 - binary_accuracy: 0.7303\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 1s 466us/step - loss: 0.5228 - binary_accuracy: 0.7319\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 1s 430us/step - loss: 0.5226 - binary_accuracy: 0.7308\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 1s 479us/step - loss: 0.5223 - binary_accuracy: 0.7313\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 1s 466us/step - loss: 0.5222 - binary_accuracy: 0.7313\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 1s 449us/step - loss: 0.5219 - binary_accuracy: 0.7335\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 1s 479us/step - loss: 0.5218 - binary_accuracy: 0.7324\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 1s 452us/step - loss: 0.5215 - binary_accuracy: 0.7340\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 1s 436us/step - loss: 0.5212 - binary_accuracy: 0.7335\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 1s 467us/step - loss: 0.5212 - binary_accuracy: 0.7319\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 1s 415us/step - loss: 0.5209 - binary_accuracy: 0.7329\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 1s 407us/step - loss: 0.5206 - binary_accuracy: 0.7345\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 1s 401us/step - loss: 0.5204 - binary_accuracy: 0.7345\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 1s 401us/step - loss: 0.5202 - binary_accuracy: 0.7367\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 1s 410us/step - loss: 0.5200 - binary_accuracy: 0.7351\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 1s 404us/step - loss: 0.5197 - binary_accuracy: 0.7361\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 1s 403us/step - loss: 0.5195 - binary_accuracy: 0.7372\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 1s 408us/step - loss: 0.5193 - binary_accuracy: 0.7372\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 1s 411us/step - loss: 0.5190 - binary_accuracy: 0.7372\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 1s 425us/step - loss: 0.5188 - binary_accuracy: 0.7383\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 1s 408us/step - loss: 0.5186 - binary_accuracy: 0.7377\n",
      "Epoch 47/100\n",
      "1876/1876 [==============================] - 1s 469us/step - loss: 0.5184 - binary_accuracy: 0.7388\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 1s 441us/step - loss: 0.5181 - binary_accuracy: 0.7393\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 1s 449us/step - loss: 0.5179 - binary_accuracy: 0.7393\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 1s 439us/step - loss: 0.5177 - binary_accuracy: 0.7383\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 1s 438us/step - loss: 0.5174 - binary_accuracy: 0.7393\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 1s 444us/step - loss: 0.5172 - binary_accuracy: 0.7393\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 1s 442us/step - loss: 0.5170 - binary_accuracy: 0.7393\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 1s 456us/step - loss: 0.5165 - binary_accuracy: 0.7393\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 1s 417us/step - loss: 0.5164 - binary_accuracy: 0.7388\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 1s 409us/step - loss: 0.5161 - binary_accuracy: 0.7393\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 1s 401us/step - loss: 0.5160 - binary_accuracy: 0.7404\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 1s 408us/step - loss: 0.5157 - binary_accuracy: 0.7415\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 1s 423us/step - loss: 0.5155 - binary_accuracy: 0.7393\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 1s 417us/step - loss: 0.5153 - binary_accuracy: 0.7393\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 1s 440us/step - loss: 0.5148 - binary_accuracy: 0.7425\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 1s 545us/step - loss: 0.5149 - binary_accuracy: 0.7409\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 1s 424us/step - loss: 0.5146 - binary_accuracy: 0.7393\n",
      "Epoch 64/100\n",
      "1876/1876 [==============================] - 1s 466us/step - loss: 0.5143 - binary_accuracy: 0.7425\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 1s 440us/step - loss: 0.5141 - binary_accuracy: 0.7399\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 1s 474us/step - loss: 0.5139 - binary_accuracy: 0.7399\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 1s 425us/step - loss: 0.5135 - binary_accuracy: 0.7399\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 1s 465us/step - loss: 0.5134 - binary_accuracy: 0.7409\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 1s 463us/step - loss: 0.5131 - binary_accuracy: 0.7393\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 1s 479us/step - loss: 0.5130 - binary_accuracy: 0.7399\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 1s 456us/step - loss: 0.5126 - binary_accuracy: 0.7393\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 1s 444us/step - loss: 0.5124 - binary_accuracy: 0.7393\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 1s 492us/step - loss: 0.5119 - binary_accuracy: 0.7383\n",
      "Epoch 74/100\n",
      "1876/1876 [==============================] - 1s 450us/step - loss: 0.5119 - binary_accuracy: 0.7388\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 1s 460us/step - loss: 0.5114 - binary_accuracy: 0.7372\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 1s 502us/step - loss: 0.5112 - binary_accuracy: 0.7377\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 1s 425us/step - loss: 0.5109 - binary_accuracy: 0.7372\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 1s 415us/step - loss: 0.5106 - binary_accuracy: 0.7377\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 1s 417us/step - loss: 0.5104 - binary_accuracy: 0.7388\n",
      "Epoch 80/100\n",
      "1876/1876 [==============================] - 1s 482us/step - loss: 0.5101 - binary_accuracy: 0.7393\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 1s 495us/step - loss: 0.5100 - binary_accuracy: 0.7399\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 1s 433us/step - loss: 0.5097 - binary_accuracy: 0.7388\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 1s 456us/step - loss: 0.5093 - binary_accuracy: 0.7409\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 1s 430us/step - loss: 0.5089 - binary_accuracy: 0.7393\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 1s 414us/step - loss: 0.5087 - binary_accuracy: 0.7409\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 1s 425us/step - loss: 0.5084 - binary_accuracy: 0.7393\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 1s 431us/step - loss: 0.5081 - binary_accuracy: 0.7388\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 1s 425us/step - loss: 0.5077 - binary_accuracy: 0.7409\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 1s 420us/step - loss: 0.5075 - binary_accuracy: 0.7404\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 1s 429us/step - loss: 0.5071 - binary_accuracy: 0.7393\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 1s 404us/step - loss: 0.5069 - binary_accuracy: 0.7383\n",
      "Epoch 92/100\n",
      "1876/1876 [==============================] - 1s 435us/step - loss: 0.5064 - binary_accuracy: 0.7393\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 1s 435us/step - loss: 0.5063 - binary_accuracy: 0.7388\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 1s 422us/step - loss: 0.5058 - binary_accuracy: 0.7404\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 1s 412us/step - loss: 0.5057 - binary_accuracy: 0.7399\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 1s 431us/step - loss: 0.5051 - binary_accuracy: 0.7409\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 1s 430us/step - loss: 0.5051 - binary_accuracy: 0.7393\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 1s 445us/step - loss: 0.5046 - binary_accuracy: 0.7404\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 1s 442us/step - loss: 0.5045 - binary_accuracy: 0.7425\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 1s 414us/step - loss: 0.5041 - binary_accuracy: 0.7409\n",
      "Epoch 1/100\n",
      "1876/1876 [==============================] - 1s 730us/step - loss: 0.5117 - binary_accuracy: 0.7431\n",
      "Epoch 2/100\n",
      "1876/1876 [==============================] - 1s 770us/step - loss: 0.5085 - binary_accuracy: 0.7457\n",
      "Epoch 3/100\n",
      "1876/1876 [==============================] - 1s 780us/step - loss: 0.5073 - binary_accuracy: 0.7468\n",
      "Epoch 4/100\n",
      "1876/1876 [==============================] - 1s 726us/step - loss: 0.5069 - binary_accuracy: 0.7484\n",
      "Epoch 5/100\n",
      "1876/1876 [==============================] - 1s 776us/step - loss: 0.5059 - binary_accuracy: 0.7473\n",
      "Epoch 6/100\n",
      "1876/1876 [==============================] - 2s 807us/step - loss: 0.5057 - binary_accuracy: 0.7484\n",
      "Epoch 7/100\n",
      "1876/1876 [==============================] - 1s 773us/step - loss: 0.5049 - binary_accuracy: 0.7468\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 1s 755us/step - loss: 0.5047 - binary_accuracy: 0.7484\n",
      "Epoch 9/100\n",
      "1876/1876 [==============================] - 1s 799us/step - loss: 0.5040 - binary_accuracy: 0.7484\n",
      "Epoch 10/100\n",
      "1876/1876 [==============================] - 2s 837us/step - loss: 0.5039 - binary_accuracy: 0.7527\n",
      "Epoch 11/100\n",
      "1876/1876 [==============================] - 2s 973us/step - loss: 0.5033 - binary_accuracy: 0.7543\n",
      "Epoch 12/100\n",
      "1876/1876 [==============================] - 1s 705us/step - loss: 0.5031 - binary_accuracy: 0.7532\n",
      "Epoch 13/100\n",
      "1876/1876 [==============================] - 1s 727us/step - loss: 0.5023 - binary_accuracy: 0.7564\n",
      "Epoch 14/100\n",
      "1876/1876 [==============================] - 1s 745us/step - loss: 0.5020 - binary_accuracy: 0.7543\n",
      "Epoch 15/100\n",
      "1876/1876 [==============================] - 1s 748us/step - loss: 0.5014 - binary_accuracy: 0.7553\n",
      "Epoch 16/100\n",
      "1876/1876 [==============================] - 1s 749us/step - loss: 0.5012 - binary_accuracy: 0.7553\n",
      "Epoch 17/100\n",
      "1876/1876 [==============================] - 1s 744us/step - loss: 0.5006 - binary_accuracy: 0.7585\n",
      "Epoch 18/100\n",
      "1876/1876 [==============================] - 1s 780us/step - loss: 0.5001 - binary_accuracy: 0.7559\n",
      "Epoch 19/100\n",
      "1876/1876 [==============================] - 2s 1ms/step - loss: 0.4997 - binary_accuracy: 0.7559\n",
      "Epoch 20/100\n",
      "1876/1876 [==============================] - 2s 1ms/step - loss: 0.4994 - binary_accuracy: 0.7564\n",
      "Epoch 21/100\n",
      "1876/1876 [==============================] - 2s 952us/step - loss: 0.4989 - binary_accuracy: 0.7532\n",
      "Epoch 22/100\n",
      "1876/1876 [==============================] - 2s 822us/step - loss: 0.4987 - binary_accuracy: 0.7532\n",
      "Epoch 23/100\n",
      "1876/1876 [==============================] - 1s 732us/step - loss: 0.4982 - binary_accuracy: 0.7532\n",
      "Epoch 24/100\n",
      "1876/1876 [==============================] - 1s 783us/step - loss: 0.4979 - binary_accuracy: 0.7521\n",
      "Epoch 25/100\n",
      "1876/1876 [==============================] - 1s 729us/step - loss: 0.4974 - binary_accuracy: 0.7527\n",
      "Epoch 26/100\n",
      "1876/1876 [==============================] - 2s 800us/step - loss: 0.4972 - binary_accuracy: 0.7537\n",
      "Epoch 27/100\n",
      "1876/1876 [==============================] - 2s 825us/step - loss: 0.4969 - binary_accuracy: 0.7532\n",
      "Epoch 28/100\n",
      "1876/1876 [==============================] - 2s 848us/step - loss: 0.4963 - binary_accuracy: 0.7532\n",
      "Epoch 29/100\n",
      "1876/1876 [==============================] - 2s 816us/step - loss: 0.4962 - binary_accuracy: 0.7553\n",
      "Epoch 30/100\n",
      "1876/1876 [==============================] - 1s 731us/step - loss: 0.4958 - binary_accuracy: 0.7553\n",
      "Epoch 31/100\n",
      "1876/1876 [==============================] - 1s 714us/step - loss: 0.4954 - binary_accuracy: 0.7569\n",
      "Epoch 32/100\n",
      "1876/1876 [==============================] - 1s 704us/step - loss: 0.4952 - binary_accuracy: 0.7559\n",
      "Epoch 33/100\n",
      "1876/1876 [==============================] - 1s 738us/step - loss: 0.4948 - binary_accuracy: 0.7569\n",
      "Epoch 34/100\n",
      "1876/1876 [==============================] - 1s 739us/step - loss: 0.4946 - binary_accuracy: 0.7580\n",
      "Epoch 35/100\n",
      "1876/1876 [==============================] - 1s 769us/step - loss: 0.4943 - binary_accuracy: 0.7564\n",
      "Epoch 36/100\n",
      "1876/1876 [==============================] - 1s 725us/step - loss: 0.4941 - binary_accuracy: 0.7575\n",
      "Epoch 37/100\n",
      "1876/1876 [==============================] - 1s 734us/step - loss: 0.4939 - binary_accuracy: 0.7553\n",
      "Epoch 38/100\n",
      "1876/1876 [==============================] - 1s 731us/step - loss: 0.4933 - binary_accuracy: 0.7564\n",
      "Epoch 39/100\n",
      "1876/1876 [==============================] - 1s 705us/step - loss: 0.4930 - binary_accuracy: 0.7564\n",
      "Epoch 40/100\n",
      "1876/1876 [==============================] - 1s 720us/step - loss: 0.4928 - binary_accuracy: 0.7564\n",
      "Epoch 41/100\n",
      "1876/1876 [==============================] - 1s 737us/step - loss: 0.4921 - binary_accuracy: 0.7564\n",
      "Epoch 42/100\n",
      "1876/1876 [==============================] - 1s 703us/step - loss: 0.4920 - binary_accuracy: 0.7564\n",
      "Epoch 43/100\n",
      "1876/1876 [==============================] - 1s 721us/step - loss: 0.4917 - binary_accuracy: 0.7591\n",
      "Epoch 44/100\n",
      "1876/1876 [==============================] - 1s 710us/step - loss: 0.4914 - binary_accuracy: 0.7580\n",
      "Epoch 45/100\n",
      "1876/1876 [==============================] - 1s 783us/step - loss: 0.4908 - binary_accuracy: 0.7591\n",
      "Epoch 46/100\n",
      "1876/1876 [==============================] - 1s 765us/step - loss: 0.4905 - binary_accuracy: 0.7575\n",
      "Epoch 47/100\n",
      "1876/1876 [==============================] - 1s 731us/step - loss: 0.4902 - binary_accuracy: 0.7575\n",
      "Epoch 48/100\n",
      "1876/1876 [==============================] - 1s 753us/step - loss: 0.4900 - binary_accuracy: 0.7564\n",
      "Epoch 49/100\n",
      "1876/1876 [==============================] - 2s 814us/step - loss: 0.4894 - binary_accuracy: 0.7575\n",
      "Epoch 50/100\n",
      "1876/1876 [==============================] - 2s 827us/step - loss: 0.4890 - binary_accuracy: 0.7580\n",
      "Epoch 51/100\n",
      "1876/1876 [==============================] - 1s 791us/step - loss: 0.4886 - binary_accuracy: 0.7585\n",
      "Epoch 52/100\n",
      "1876/1876 [==============================] - 1s 777us/step - loss: 0.4882 - binary_accuracy: 0.7580\n",
      "Epoch 53/100\n",
      "1876/1876 [==============================] - 1s 769us/step - loss: 0.4878 - binary_accuracy: 0.7596\n",
      "Epoch 54/100\n",
      "1876/1876 [==============================] - 1s 789us/step - loss: 0.4872 - binary_accuracy: 0.7580\n",
      "Epoch 55/100\n",
      "1876/1876 [==============================] - 2s 819us/step - loss: 0.4869 - binary_accuracy: 0.7569\n",
      "Epoch 56/100\n",
      "1876/1876 [==============================] - 1s 685us/step - loss: 0.4867 - binary_accuracy: 0.7575\n",
      "Epoch 57/100\n",
      "1876/1876 [==============================] - 1s 702us/step - loss: 0.4862 - binary_accuracy: 0.7591\n",
      "Epoch 58/100\n",
      "1876/1876 [==============================] - 1s 780us/step - loss: 0.4854 - binary_accuracy: 0.7612\n",
      "Epoch 59/100\n",
      "1876/1876 [==============================] - 1s 782us/step - loss: 0.4851 - binary_accuracy: 0.7628\n",
      "Epoch 60/100\n",
      "1876/1876 [==============================] - 2s 1ms/step - loss: 0.4849 - binary_accuracy: 0.7612\n",
      "Epoch 61/100\n",
      "1876/1876 [==============================] - 1s 744us/step - loss: 0.4843 - binary_accuracy: 0.7639\n",
      "Epoch 62/100\n",
      "1876/1876 [==============================] - 1s 691us/step - loss: 0.4839 - binary_accuracy: 0.7639\n",
      "Epoch 63/100\n",
      "1876/1876 [==============================] - 1s 705us/step - loss: 0.4838 - binary_accuracy: 0.7617\n",
      "Epoch 64/100\n",
      "1876/1876 [==============================] - 1s 720us/step - loss: 0.4844 - binary_accuracy: 0.7601\n",
      "Epoch 65/100\n",
      "1876/1876 [==============================] - 1s 688us/step - loss: 0.4892 - binary_accuracy: 0.7617\n",
      "Epoch 66/100\n",
      "1876/1876 [==============================] - 1s 703us/step - loss: 0.4817 - binary_accuracy: 0.7644\n",
      "Epoch 67/100\n",
      "1876/1876 [==============================] - 1s 707us/step - loss: 0.4813 - binary_accuracy: 0.7671\n",
      "Epoch 68/100\n",
      "1876/1876 [==============================] - 1s 724us/step - loss: 0.4809 - binary_accuracy: 0.7687\n",
      "Epoch 69/100\n",
      "1876/1876 [==============================] - 1s 693us/step - loss: 0.4804 - binary_accuracy: 0.7676\n",
      "Epoch 70/100\n",
      "1876/1876 [==============================] - 1s 699us/step - loss: 0.4800 - binary_accuracy: 0.7671\n",
      "Epoch 71/100\n",
      "1876/1876 [==============================] - 1s 690us/step - loss: 0.4794 - binary_accuracy: 0.7671\n",
      "Epoch 72/100\n",
      "1876/1876 [==============================] - 1s 696us/step - loss: 0.4788 - binary_accuracy: 0.7676\n",
      "Epoch 73/100\n",
      "1876/1876 [==============================] - 1s 708us/step - loss: 0.4786 - binary_accuracy: 0.7687\n",
      "Epoch 74/100\n",
      "1876/1876 [==============================] - 1s 696us/step - loss: 0.4780 - binary_accuracy: 0.7665\n",
      "Epoch 75/100\n",
      "1876/1876 [==============================] - 1s 726us/step - loss: 0.4772 - binary_accuracy: 0.7681\n",
      "Epoch 76/100\n",
      "1876/1876 [==============================] - 1s 751us/step - loss: 0.4769 - binary_accuracy: 0.7692\n",
      "Epoch 77/100\n",
      "1876/1876 [==============================] - 1s 702us/step - loss: 0.4762 - binary_accuracy: 0.7719\n",
      "Epoch 78/100\n",
      "1876/1876 [==============================] - 1s 717us/step - loss: 0.4759 - binary_accuracy: 0.7708\n",
      "Epoch 79/100\n",
      "1876/1876 [==============================] - 1s 682us/step - loss: 0.4746 - binary_accuracy: 0.7681\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1876/1876 [==============================] - 1s 685us/step - loss: 0.4743 - binary_accuracy: 0.7671\n",
      "Epoch 81/100\n",
      "1876/1876 [==============================] - 1s 682us/step - loss: 0.4727 - binary_accuracy: 0.7665\n",
      "Epoch 82/100\n",
      "1876/1876 [==============================] - 1s 682us/step - loss: 0.4729 - binary_accuracy: 0.7681\n",
      "Epoch 83/100\n",
      "1876/1876 [==============================] - 1s 684us/step - loss: 0.4728 - binary_accuracy: 0.7676\n",
      "Epoch 84/100\n",
      "1876/1876 [==============================] - 1s 679us/step - loss: 0.4776 - binary_accuracy: 0.7660\n",
      "Epoch 85/100\n",
      "1876/1876 [==============================] - 1s 688us/step - loss: 0.4705 - binary_accuracy: 0.7697\n",
      "Epoch 86/100\n",
      "1876/1876 [==============================] - 1s 736us/step - loss: 0.4699 - binary_accuracy: 0.7697\n",
      "Epoch 87/100\n",
      "1876/1876 [==============================] - 2s 869us/step - loss: 0.4696 - binary_accuracy: 0.7719\n",
      "Epoch 88/100\n",
      "1876/1876 [==============================] - 2s 1ms/step - loss: 0.4682 - binary_accuracy: 0.7719\n",
      "Epoch 89/100\n",
      "1876/1876 [==============================] - 1s 793us/step - loss: 0.4681 - binary_accuracy: 0.7719\n",
      "Epoch 90/100\n",
      "1876/1876 [==============================] - 2s 920us/step - loss: 0.4674 - binary_accuracy: 0.7724\n",
      "Epoch 91/100\n",
      "1876/1876 [==============================] - 2s 819us/step - loss: 0.4677 - binary_accuracy: 0.7713\n",
      "Epoch 92/100\n",
      "1876/1876 [==============================] - 1s 770us/step - loss: 0.4665 - binary_accuracy: 0.7719\n",
      "Epoch 93/100\n",
      "1876/1876 [==============================] - 1s 750us/step - loss: 0.4653 - binary_accuracy: 0.7724\n",
      "Epoch 94/100\n",
      "1876/1876 [==============================] - 1s 768us/step - loss: 0.4649 - binary_accuracy: 0.7735\n",
      "Epoch 95/100\n",
      "1876/1876 [==============================] - 1s 751us/step - loss: 0.4646 - binary_accuracy: 0.7724\n",
      "Epoch 96/100\n",
      "1876/1876 [==============================] - 1s 776us/step - loss: 0.4635 - binary_accuracy: 0.7740\n",
      "Epoch 97/100\n",
      "1876/1876 [==============================] - 1s 758us/step - loss: 0.4634 - binary_accuracy: 0.7724\n",
      "Epoch 98/100\n",
      "1876/1876 [==============================] - 2s 870us/step - loss: 0.4632 - binary_accuracy: 0.7740\n",
      "Epoch 99/100\n",
      "1876/1876 [==============================] - 2s 806us/step - loss: 0.4619 - binary_accuracy: 0.7772\n",
      "Epoch 100/100\n",
      "1876/1876 [==============================] - 1s 761us/step - loss: 0.4623 - binary_accuracy: 0.7724\n"
     ]
    }
   ],
   "source": [
    "batch_list = [134, 67, 28, 14, 7, 4]\n",
    "for num in batch_list:\n",
    "    classifier.fit(X_train, y_train, batch_size=num, \n",
    "                   epochs=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:36:07.635980Z",
     "start_time": "2018-11-01T03:36:07.366800Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:36:08.468246Z",
     "start_time": "2018-11-01T03:36:08.440692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73, 28],\n",
       "       [33, 66]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:36:09.594897Z",
     "start_time": "2018-11-01T03:36:09.567941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 69.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy = {(cm[0][0]+cm[1][1])/(cm.sum())/.01}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75.5% Accuracy on 1824 training, 200 test\n",
    "__3 layers__\n",
    "- layer 1 = ReLU X 7\n",
    "- layer 2 = SoftMax X 14\n",
    "- layer 3 = ReLU X 7\n",
    "- output layer = Sigmoid X 1\n",
    "\n",
    "__metrics__ = Cosine\n",
    "\n",
    "__loss__ = binary_crossentropy\n",
    "\n",
    "__Optimizer__ = Nadam\n",
    "\n",
    "__Batch size__ = 12\n",
    "\n",
    "__Epochs__ = 175\n",
    "\n",
    "no __diff__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T02:47:51.033028Z",
     "start_time": "2018-11-01T02:47:51.008356Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=_classifier, batch_size=12, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:01:42.422218Z",
     "start_time": "2018-11-01T02:47:51.405705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 532us/step - loss: 0.6931 - acc: 0.5148\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6359 - acc: 0.6742\n",
      "Epoch 3/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5818 - acc: 0.7062\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5709 - acc: 0.7020\n",
      "Epoch 5/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5660 - acc: 0.7026\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5627 - acc: 0.7056\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5603 - acc: 0.6985\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5589 - acc: 0.7038\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5569 - acc: 0.7133\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5570 - acc: 0.7050\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 288us/step - loss: 0.5560 - acc: 0.7056\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5555 - acc: 0.7085\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5555 - acc: 0.7050\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5550 - acc: 0.7085\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5541 - acc: 0.7068\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5544 - acc: 0.7044\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5538 - acc: 0.7073\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5539 - acc: 0.7103\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5534 - acc: 0.7038\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5539 - acc: 0.7073\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.5530 - acc: 0.7073\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5534 - acc: 0.7109\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5518 - acc: 0.7044\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5527 - acc: 0.7056\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5522 - acc: 0.7073\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5518 - acc: 0.7079\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.5516 - acc: 0.7109\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5513 - acc: 0.7026\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.5512 - acc: 0.7062\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5506 - acc: 0.7050\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5506 - acc: 0.7073\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5508 - acc: 0.7002\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5509 - acc: 0.7079\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5498 - acc: 0.7079\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5500 - acc: 0.7002\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.5499 - acc: 0.7038\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.5499 - acc: 0.7038\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.5487 - acc: 0.7062\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5492 - acc: 0.7050\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 287us/step - loss: 0.5495 - acc: 0.7044\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.5485 - acc: 0.7062\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5490 - acc: 0.7038\n",
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.5484 - acc: 0.7026\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.5482 - acc: 0.7026\n",
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.5479 - acc: 0.6991\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 276us/step - loss: 0.5464 - acc: 0.7085\n",
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.5479 - acc: 0.7073\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.5482 - acc: 0.7097\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 284us/step - loss: 0.5470 - acc: 0.7038\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 276us/step - loss: 0.5464 - acc: 0.7085\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.5472 - acc: 0.7139\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.5465 - acc: 0.7073\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.5464 - acc: 0.7115\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5464 - acc: 0.7133\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.5455 - acc: 0.7085\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5451 - acc: 0.7103\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.5458 - acc: 0.7103\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 273us/step - loss: 0.5453 - acc: 0.7085\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.5458 - acc: 0.7032\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5448 - acc: 0.7085\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5445 - acc: 0.7050\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 1s 475us/step - loss: 0.5452 - acc: 0.7150\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 1s 418us/step - loss: 0.5436 - acc: 0.7145\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 1s 312us/step - loss: 0.5440 - acc: 0.7198\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.5453 - acc: 0.7139\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.5440 - acc: 0.7139\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 290us/step - loss: 0.5433 - acc: 0.7103\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 281us/step - loss: 0.5439 - acc: 0.7109\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 283us/step - loss: 0.5434 - acc: 0.7091\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 256us/step - loss: 0.5436 - acc: 0.7168\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 1s 409us/step - loss: 0.5439 - acc: 0.7085\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 1s 342us/step - loss: 0.5427 - acc: 0.7145\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 1s 433us/step - loss: 0.5434 - acc: 0.7174\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 1s 304us/step - loss: 0.5436 - acc: 0.7091\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5425 - acc: 0.7168\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5428 - acc: 0.7115\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5421 - acc: 0.7097\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5425 - acc: 0.7062\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5421 - acc: 0.7109\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5412 - acc: 0.7127\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5425 - acc: 0.7162\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5423 - acc: 0.7115\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5436 - acc: 0.7115\n",
      "Epoch 84/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5427 - acc: 0.7162\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5407 - acc: 0.7180\n",
      "Epoch 86/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5422 - acc: 0.7109\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5417 - acc: 0.7145\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5406 - acc: 0.7162\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5425 - acc: 0.7156\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5416 - acc: 0.7127\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5409 - acc: 0.7150\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5407 - acc: 0.7174\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5398 - acc: 0.7156\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5412 - acc: 0.7139\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5412 - acc: 0.7156\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5397 - acc: 0.7180\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5407 - acc: 0.7186\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5403 - acc: 0.7180\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5397 - acc: 0.7198\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5390 - acc: 0.7162\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5405 - acc: 0.7168\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5388 - acc: 0.7180\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5407 - acc: 0.7186\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 206us/step - loss: 0.5399 - acc: 0.7145\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.5389 - acc: 0.7168\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5389 - acc: 0.7127\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5400 - acc: 0.7204\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.5384 - acc: 0.7139\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5390 - acc: 0.7239\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5392 - acc: 0.7186\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5391 - acc: 0.7097\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5396 - acc: 0.7133\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5383 - acc: 0.7150\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5387 - acc: 0.7174\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5377 - acc: 0.7204\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5376 - acc: 0.7156\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5382 - acc: 0.7186\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5387 - acc: 0.7210\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5385 - acc: 0.7174\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5372 - acc: 0.7216\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5382 - acc: 0.7198\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 207us/step - loss: 0.5372 - acc: 0.7121\n",
      "Epoch 123/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5368 - acc: 0.7186\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5366 - acc: 0.7192\n",
      "Epoch 125/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5384 - acc: 0.7139\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.5376 - acc: 0.7239\n",
      "Epoch 127/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5380 - acc: 0.7192\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5387 - acc: 0.7233\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5366 - acc: 0.7204\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5367 - acc: 0.7174\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.5371 - acc: 0.7174\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5367 - acc: 0.7257\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5376 - acc: 0.7198\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5361 - acc: 0.7186\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5380 - acc: 0.7174\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5363 - acc: 0.7180\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5366 - acc: 0.7216\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5364 - acc: 0.7156\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5359 - acc: 0.7251\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5370 - acc: 0.7192\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5361 - acc: 0.7227\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5369 - acc: 0.7198\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5343 - acc: 0.7251\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5359 - acc: 0.7222\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5358 - acc: 0.7216\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5353 - acc: 0.7222\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 210us/step - loss: 0.5361 - acc: 0.7281\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5364 - acc: 0.7186\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5360 - acc: 0.7174\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5358 - acc: 0.7227\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5345 - acc: 0.7162\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5348 - acc: 0.7233\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5349 - acc: 0.7239\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5355 - acc: 0.7139\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5357 - acc: 0.7210\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5368 - acc: 0.7210\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5351 - acc: 0.7233\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5362 - acc: 0.7216\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5348 - acc: 0.7210\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5355 - acc: 0.7186\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5344 - acc: 0.7145\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5342 - acc: 0.7210\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5354 - acc: 0.7091\n",
      "Epoch 164/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5335 - acc: 0.7227\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5334 - acc: 0.7133\n",
      "Epoch 166/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5328 - acc: 0.7192\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5337 - acc: 0.7210\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5325 - acc: 0.7245\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5338 - acc: 0.7210\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5333 - acc: 0.7121\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5336 - acc: 0.7198\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5324 - acc: 0.7216\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5334 - acc: 0.7192\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5320 - acc: 0.7198\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5332 - acc: 0.7162\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5322 - acc: 0.7269\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5322 - acc: 0.7168\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5322 - acc: 0.7204\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5309 - acc: 0.7222\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5307 - acc: 0.7233\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5337 - acc: 0.7180\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5319 - acc: 0.7156\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5308 - acc: 0.7162\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5315 - acc: 0.7227\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5328 - acc: 0.7115\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5306 - acc: 0.7192\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.5312 - acc: 0.7174\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5305 - acc: 0.7198\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5294 - acc: 0.7251\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5301 - acc: 0.7222\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5301 - acc: 0.7239\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5300 - acc: 0.7222\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5306 - acc: 0.7192\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5308 - acc: 0.7233\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5290 - acc: 0.7222\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5289 - acc: 0.7233\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 205us/step - loss: 0.5291 - acc: 0.7145\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5279 - acc: 0.7133\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5296 - acc: 0.7222\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5292 - acc: 0.7192\n",
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 547us/step - loss: 0.6932 - acc: 0.4846\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5012\n",
      "Epoch 3/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.4953\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 5/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 291us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 1s 299us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 1s 317us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 277us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 1s 297us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 277us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 274us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 273us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 1s 297us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 274us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 285us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 1s 298us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 256us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.5071\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 283us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 82/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 256us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 84/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 86/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 1s 320us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 195us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 1s 316us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 196us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 201us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 192us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 199us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 197us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 198us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 198us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 203us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 1s 332us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 1s 297us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 292us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 1s 413us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 123/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 125/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 127/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 276us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 275us/step - loss: 0.6933 - acc: 0.5071\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.6933 - acc: 0.5071\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 208us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 162/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 164/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 166/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5071\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 280us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 271us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 0s 295us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.4905\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 292us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 256us/step - loss: 0.6931 - acc: 0.5071\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5071\n",
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 573us/step - loss: 0.6933 - acc: 0.4970\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.6474 - acc: 0.6463\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5701 - acc: 0.7068\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5616 - acc: 0.7139\n",
      "Epoch 5/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5586 - acc: 0.7174\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5569 - acc: 0.7133\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5556 - acc: 0.7068\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5542 - acc: 0.7162\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5542 - acc: 0.7139\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5530 - acc: 0.7062\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5526 - acc: 0.7091\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 1s 299us/step - loss: 0.5521 - acc: 0.7162\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.5506 - acc: 0.7133\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 1s 312us/step - loss: 0.5519 - acc: 0.7062\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 280us/step - loss: 0.5518 - acc: 0.7091\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 263us/step - loss: 0.5515 - acc: 0.7097\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5505 - acc: 0.7062\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5521 - acc: 0.7097\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5507 - acc: 0.7198\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5506 - acc: 0.7032\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5498 - acc: 0.7079\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5512 - acc: 0.7085\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5496 - acc: 0.7109\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5498 - acc: 0.7127\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5494 - acc: 0.7139\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5502 - acc: 0.7079\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5487 - acc: 0.7109\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.5483 - acc: 0.7192\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5493 - acc: 0.7062\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.5480 - acc: 0.7174\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5488 - acc: 0.7097\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5475 - acc: 0.7168\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5475 - acc: 0.7127\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5462 - acc: 0.7109\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5472 - acc: 0.7091\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5465 - acc: 0.7085\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5470 - acc: 0.7109\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5464 - acc: 0.7115\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5467 - acc: 0.7121\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5455 - acc: 0.7150\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5459 - acc: 0.7162\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5455 - acc: 0.7133\n",
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5459 - acc: 0.7139\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5452 - acc: 0.7133\n",
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5445 - acc: 0.7145\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5446 - acc: 0.7210\n",
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5447 - acc: 0.7204\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5442 - acc: 0.7145\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5429 - acc: 0.7263\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5430 - acc: 0.7162\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5438 - acc: 0.7168\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5431 - acc: 0.7198\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5437 - acc: 0.7168\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5440 - acc: 0.7079\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5430 - acc: 0.7139\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5426 - acc: 0.7133\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.5438 - acc: 0.7156\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 287us/step - loss: 0.5420 - acc: 0.7174\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.5431 - acc: 0.7139\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5424 - acc: 0.7133\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.5412 - acc: 0.7180\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5425 - acc: 0.7174\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5417 - acc: 0.7174\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5407 - acc: 0.7186\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5423 - acc: 0.7097\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5427 - acc: 0.7192\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5408 - acc: 0.7198\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5395 - acc: 0.7174\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 273us/step - loss: 0.5420 - acc: 0.7103\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.5408 - acc: 0.7150\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5409 - acc: 0.7222\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5402 - acc: 0.7162\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 1s 305us/step - loss: 0.5414 - acc: 0.7150\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.5408 - acc: 0.7204\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5399 - acc: 0.7192\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5400 - acc: 0.7150\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 265us/step - loss: 0.5413 - acc: 0.7192\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 283us/step - loss: 0.5394 - acc: 0.7192\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 273us/step - loss: 0.5401 - acc: 0.7192\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 287us/step - loss: 0.5399 - acc: 0.7139\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.5396 - acc: 0.7162\n",
      "Epoch 82/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5396 - acc: 0.7233\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.5398 - acc: 0.7121\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5402 - acc: 0.7103\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 289us/step - loss: 0.5405 - acc: 0.7103\n",
      "Epoch 86/200\n",
      "1688/1688 [==============================] - 0s 294us/step - loss: 0.5391 - acc: 0.7198\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5393 - acc: 0.7162\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5400 - acc: 0.7133\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5390 - acc: 0.7198\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 208us/step - loss: 0.5398 - acc: 0.7198\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 209us/step - loss: 0.5394 - acc: 0.7156\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5382 - acc: 0.7150\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.5394 - acc: 0.7145\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5409 - acc: 0.7180\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5393 - acc: 0.7168\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5387 - acc: 0.7180\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5393 - acc: 0.7133\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.5377 - acc: 0.7245\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5393 - acc: 0.7198\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.5385 - acc: 0.7216\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5391 - acc: 0.7192\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 277us/step - loss: 0.5381 - acc: 0.7168\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5388 - acc: 0.7156\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.5390 - acc: 0.7198\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5385 - acc: 0.7162\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5382 - acc: 0.7168\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5390 - acc: 0.7222\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5394 - acc: 0.7139\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5387 - acc: 0.7139\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5386 - acc: 0.7186\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5385 - acc: 0.7186\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5394 - acc: 0.7139\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.5373 - acc: 0.7186\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5391 - acc: 0.7156\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5372 - acc: 0.7204\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5397 - acc: 0.7139\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5372 - acc: 0.7198\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5379 - acc: 0.7210\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5381 - acc: 0.7139\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5383 - acc: 0.7222\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5374 - acc: 0.7180\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 208us/step - loss: 0.5369 - acc: 0.7222\n",
      "Epoch 123/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5375 - acc: 0.7210\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5375 - acc: 0.7251\n",
      "Epoch 125/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.5382 - acc: 0.7198\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5380 - acc: 0.7150\n",
      "Epoch 127/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5372 - acc: 0.7210\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5378 - acc: 0.7192\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5379 - acc: 0.7198\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5369 - acc: 0.7204\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5365 - acc: 0.7186\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5373 - acc: 0.7168\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5371 - acc: 0.7174\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5383 - acc: 0.7192\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5371 - acc: 0.7115\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5381 - acc: 0.7216\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5363 - acc: 0.7127\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5366 - acc: 0.7133\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5367 - acc: 0.7186\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 273us/step - loss: 0.5358 - acc: 0.7186\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5362 - acc: 0.7174\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5376 - acc: 0.7222\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5365 - acc: 0.7233\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5369 - acc: 0.7180\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5364 - acc: 0.7210\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 211us/step - loss: 0.5359 - acc: 0.7245\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5357 - acc: 0.7227\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5364 - acc: 0.7216\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5361 - acc: 0.7210\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5360 - acc: 0.7216\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5339 - acc: 0.7245\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5372 - acc: 0.7156\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5354 - acc: 0.7227\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5351 - acc: 0.7233\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5350 - acc: 0.7192\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.5355 - acc: 0.7216\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5344 - acc: 0.7263\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5346 - acc: 0.7233\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 285us/step - loss: 0.5356 - acc: 0.7216\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5331 - acc: 0.7251\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5350 - acc: 0.7257\n",
      "Epoch 162/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5367 - acc: 0.7186\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5336 - acc: 0.7227\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5343 - acc: 0.7174\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5344 - acc: 0.7269\n",
      "Epoch 166/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5337 - acc: 0.7263\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5335 - acc: 0.7168\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.5339 - acc: 0.7275\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.5340 - acc: 0.7222\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5336 - acc: 0.7233\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5328 - acc: 0.7293\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5342 - acc: 0.7204\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5326 - acc: 0.7251\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5337 - acc: 0.7192\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5333 - acc: 0.7245\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5324 - acc: 0.7174\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 210us/step - loss: 0.5331 - acc: 0.7222\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.5326 - acc: 0.7233\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5321 - acc: 0.7251\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5326 - acc: 0.7257\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5332 - acc: 0.7222\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5327 - acc: 0.7263\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5325 - acc: 0.7257\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5324 - acc: 0.7293\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5310 - acc: 0.7204\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5311 - acc: 0.7245\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5324 - acc: 0.7257\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.5315 - acc: 0.7263\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.5314 - acc: 0.7210\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5314 - acc: 0.7222\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.5310 - acc: 0.7227\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5306 - acc: 0.7168\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5317 - acc: 0.7233\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5319 - acc: 0.7192\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5304 - acc: 0.7275\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5308 - acc: 0.7233\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5301 - acc: 0.7216\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.5301 - acc: 0.7281\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5299 - acc: 0.7275\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5301 - acc: 0.7275\n",
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 664us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 3/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 5/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.6933 - acc: 0.4941\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5024\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.5000\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4976\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6933 - acc: 0.5047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 292us/step - loss: 0.6932 - acc: 0.4941\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 293us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 0s 212us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.4870\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.4941\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.4893\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 82/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 84/200\n",
      "1688/1688 [==============================] - 0s 283us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 86/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.4964\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6933 - acc: 0.4858\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 0s 263us/step - loss: 0.6933 - acc: 0.4810\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 123/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 127/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.4870\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.4964\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.4941\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 283us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6933 - acc: 0.4870\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.6933 - acc: 0.4941\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 1s 375us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 288us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 162/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 164/200\n",
      "1688/1688 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 166/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.6932 - acc: 0.4929\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 278us/step - loss: 0.6933 - acc: 0.4882\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 287us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 284us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 289us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6933 - acc: 0.4964\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 1s 299us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 256us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4964\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.5047\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5047\n",
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 587us/step - loss: 0.6930 - acc: 0.5024\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6311 - acc: 0.6795\n",
      "Epoch 3/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5786 - acc: 0.7056\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5694 - acc: 0.7062\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5671 - acc: 0.7127\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5617 - acc: 0.7044\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5588 - acc: 0.7097\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5575 - acc: 0.7073\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5550 - acc: 0.7103\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5549 - acc: 0.7127\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5542 - acc: 0.7062\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5539 - acc: 0.7109\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5539 - acc: 0.7103\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5518 - acc: 0.7073\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5521 - acc: 0.7115\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5520 - acc: 0.7091\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5510 - acc: 0.7085\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5514 - acc: 0.7109\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5504 - acc: 0.7085\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5504 - acc: 0.7062\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5506 - acc: 0.7056\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5510 - acc: 0.7073\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5499 - acc: 0.7121\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5503 - acc: 0.7085\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5495 - acc: 0.7044\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5482 - acc: 0.7068\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5493 - acc: 0.7103\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5489 - acc: 0.7103\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.5480 - acc: 0.7068\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5480 - acc: 0.7085\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.5485 - acc: 0.7127\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5485 - acc: 0.7127\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5491 - acc: 0.7079\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5478 - acc: 0.7085\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5481 - acc: 0.7091\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5474 - acc: 0.7091\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5474 - acc: 0.7085\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.5472 - acc: 0.7097\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5469 - acc: 0.7150\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5467 - acc: 0.7014\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5463 - acc: 0.7097\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5470 - acc: 0.7044\n",
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5466 - acc: 0.7085\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5462 - acc: 0.7062\n",
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.5453 - acc: 0.7133\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 266us/step - loss: 0.5459 - acc: 0.7133\n",
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.5455 - acc: 0.7150\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5460 - acc: 0.7091\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5447 - acc: 0.7050\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5456 - acc: 0.7073\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5451 - acc: 0.7121\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5440 - acc: 0.7109\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5459 - acc: 0.7115\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5449 - acc: 0.7073\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5446 - acc: 0.7150\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5430 - acc: 0.7150\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.5438 - acc: 0.7127\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.5430 - acc: 0.7121\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 278us/step - loss: 0.5437 - acc: 0.7050\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5433 - acc: 0.7121\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.5435 - acc: 0.7186\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5437 - acc: 0.7097\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5421 - acc: 0.7121\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.5430 - acc: 0.7121\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5415 - acc: 0.7133\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5428 - acc: 0.7097\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 288us/step - loss: 0.5421 - acc: 0.7139\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 274us/step - loss: 0.5420 - acc: 0.7121\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5421 - acc: 0.7056\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5421 - acc: 0.7127\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5413 - acc: 0.7168\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5418 - acc: 0.7091\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 0s 281us/step - loss: 0.5410 - acc: 0.7180\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5407 - acc: 0.7109\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5418 - acc: 0.7156\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5412 - acc: 0.7174\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5407 - acc: 0.7198\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5412 - acc: 0.7156\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5409 - acc: 0.7168\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5410 - acc: 0.7145\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5405 - acc: 0.7133\n",
      "Epoch 82/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5404 - acc: 0.7162\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5406 - acc: 0.7162\n",
      "Epoch 84/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5395 - acc: 0.7174\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5410 - acc: 0.7139\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5395 - acc: 0.7210\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5397 - acc: 0.7180\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5403 - acc: 0.7168\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5400 - acc: 0.7251\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5398 - acc: 0.7150\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5386 - acc: 0.7251\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5391 - acc: 0.7145\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5384 - acc: 0.7145\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5398 - acc: 0.7156\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5390 - acc: 0.7168\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 213us/step - loss: 0.5388 - acc: 0.7198\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5390 - acc: 0.7145\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5382 - acc: 0.7145\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5387 - acc: 0.7139\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5386 - acc: 0.7186\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5383 - acc: 0.7174\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5381 - acc: 0.7186\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5380 - acc: 0.7180\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5385 - acc: 0.7281\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5379 - acc: 0.7198\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5376 - acc: 0.7097\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5383 - acc: 0.7150\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5377 - acc: 0.7204\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5385 - acc: 0.7091\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5373 - acc: 0.7145\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5381 - acc: 0.7192\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5377 - acc: 0.7204\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5371 - acc: 0.7145\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5373 - acc: 0.7192\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5363 - acc: 0.7251\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 0s 217us/step - loss: 0.5372 - acc: 0.7168\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.5355 - acc: 0.7198\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 218us/step - loss: 0.5373 - acc: 0.7233\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5369 - acc: 0.7139\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5366 - acc: 0.7216\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.5367 - acc: 0.7186\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5376 - acc: 0.7139\n",
      "Epoch 123/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5370 - acc: 0.7257\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.5370 - acc: 0.7180\n",
      "Epoch 125/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5369 - acc: 0.7216\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5357 - acc: 0.7239\n",
      "Epoch 127/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5350 - acc: 0.7174\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5363 - acc: 0.7216\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5364 - acc: 0.7162\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5358 - acc: 0.7198\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5355 - acc: 0.7239\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5367 - acc: 0.7180\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5352 - acc: 0.7168\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5360 - acc: 0.7079\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5354 - acc: 0.7210\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5347 - acc: 0.7198\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5355 - acc: 0.7233\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5365 - acc: 0.7210\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.5339 - acc: 0.7216\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5361 - acc: 0.7198\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5354 - acc: 0.7145\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5344 - acc: 0.7233\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5337 - acc: 0.7257\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 1s 310us/step - loss: 0.5355 - acc: 0.7210\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.5347 - acc: 0.7233\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.5343 - acc: 0.7073\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5342 - acc: 0.7180\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5341 - acc: 0.7180\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5343 - acc: 0.7192\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.5340 - acc: 0.7210\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5339 - acc: 0.7216\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5331 - acc: 0.7239\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.5332 - acc: 0.7210\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5340 - acc: 0.7180\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5336 - acc: 0.7204\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5339 - acc: 0.7174\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.5325 - acc: 0.7299\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5324 - acc: 0.7168\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5303 - acc: 0.7245\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5337 - acc: 0.7216\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5325 - acc: 0.7251\n",
      "Epoch 162/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5326 - acc: 0.7180\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5330 - acc: 0.7150\n",
      "Epoch 164/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5310 - acc: 0.7198\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5319 - acc: 0.7216\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5318 - acc: 0.7174\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5315 - acc: 0.7257\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5308 - acc: 0.7263\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5314 - acc: 0.7222\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.5296 - acc: 0.7198\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.5301 - acc: 0.7251\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.5294 - acc: 0.7186\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 1s 298us/step - loss: 0.5282 - acc: 0.7245\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.5292 - acc: 0.7316\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5291 - acc: 0.7281\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5299 - acc: 0.7174\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.5292 - acc: 0.7222\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.5283 - acc: 0.7204\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5290 - acc: 0.7293\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.5279 - acc: 0.7222\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.5274 - acc: 0.7257\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5280 - acc: 0.7263\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.5279 - acc: 0.7222\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.5268 - acc: 0.7251\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 259us/step - loss: 0.5277 - acc: 0.7233\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.5257 - acc: 0.7322\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.5264 - acc: 0.7239\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 253us/step - loss: 0.5259 - acc: 0.7275\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.5245 - acc: 0.7293\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5253 - acc: 0.7299\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.5252 - acc: 0.7287\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5249 - acc: 0.7257\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.5239 - acc: 0.7299\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.5235 - acc: 0.7293\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.5252 - acc: 0.7281\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.5225 - acc: 0.7352\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 215us/step - loss: 0.5243 - acc: 0.7293\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.5227 - acc: 0.7310\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.5233 - acc: 0.7239\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.5225 - acc: 0.7322\n",
      "Epoch 1/200\n",
      "1688/1688 [==============================] - 1s 632us/step - loss: 0.6932 - acc: 0.5000\n",
      "Epoch 2/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 3/200\n",
      "1688/1688 [==============================] - 0s 278us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 4/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 5/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 6/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 7/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 8/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 9/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 10/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 11/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 12/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 13/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 14/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 15/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 16/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 17/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 18/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 19/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 20/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 21/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 22/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 23/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 24/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 25/200\n",
      "1688/1688 [==============================] - 0s 222us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 26/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 27/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5012\n",
      "Epoch 28/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 29/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 30/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 31/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 32/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 33/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 34/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 35/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 36/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 37/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 38/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 39/200\n",
      "1688/1688 [==============================] - 0s 268us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 40/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 41/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 42/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 43/200\n",
      "1688/1688 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 44/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 45/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 46/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 48/200\n",
      "1688/1688 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.4953\n",
      "Epoch 49/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 50/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 51/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 52/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 53/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 54/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 55/200\n",
      "1688/1688 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 56/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 57/200\n",
      "1688/1688 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 58/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 59/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 60/200\n",
      "1688/1688 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 61/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 62/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 63/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 64/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 65/200\n",
      "1688/1688 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 66/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 67/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 68/200\n",
      "1688/1688 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 69/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 70/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 71/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 72/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 73/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 74/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 75/200\n",
      "1688/1688 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 76/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 77/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 78/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 79/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 80/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 81/200\n",
      "1688/1688 [==============================] - 0s 270us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 82/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 83/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 84/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 85/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 86/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 87/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 88/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 89/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 90/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 91/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 92/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 93/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 94/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 95/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 96/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 97/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 98/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 99/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 100/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 101/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 102/200\n",
      "1688/1688 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 103/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 104/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 105/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 106/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 107/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 108/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 109/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 110/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 111/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 112/200\n",
      "1688/1688 [==============================] - 0s 257us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 113/200\n",
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 114/200\n",
      "1688/1688 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 115/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 116/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 117/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 118/200\n",
      "1688/1688 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 119/200\n",
      "1688/1688 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 120/200\n",
      "1688/1688 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 121/200\n",
      "1688/1688 [==============================] - 0s 249us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 122/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 123/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 124/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 125/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 126/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s 254us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 128/200\n",
      "1688/1688 [==============================] - 0s 260us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 129/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 130/200\n",
      "1688/1688 [==============================] - 0s 261us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 131/200\n",
      "1688/1688 [==============================] - 0s 289us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 132/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 133/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 134/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 135/200\n",
      "1688/1688 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 136/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 137/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 138/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 139/200\n",
      "1688/1688 [==============================] - 0s 267us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 140/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 141/200\n",
      "1688/1688 [==============================] - 0s 279us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 142/200\n",
      "1688/1688 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 143/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 144/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 145/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 146/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 147/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 148/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 149/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 150/200\n",
      "1688/1688 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 151/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 152/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 153/200\n",
      "1688/1688 [==============================] - 0s 291us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 154/200\n",
      "1688/1688 [==============================] - 1s 301us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 155/200\n",
      "1688/1688 [==============================] - 0s 280us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 156/200\n",
      "1688/1688 [==============================] - 0s 262us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 157/200\n",
      "1688/1688 [==============================] - 0s 210us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 158/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 159/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 160/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 161/200\n",
      "1688/1688 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 162/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 163/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 164/200\n",
      "1688/1688 [==============================] - 0s 280us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 165/200\n",
      "1688/1688 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 166/200\n",
      "1688/1688 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 167/200\n",
      "1688/1688 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 168/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 169/200\n",
      "1688/1688 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 170/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 171/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 172/200\n",
      "1688/1688 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 173/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 174/200\n",
      "1688/1688 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 175/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 176/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 177/200\n",
      "1688/1688 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 178/200\n",
      "1688/1688 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 179/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 180/200\n",
      "1688/1688 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 181/200\n",
      "1688/1688 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 182/200\n",
      "1688/1688 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 183/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 184/200\n",
      "1688/1688 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 185/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 186/200\n",
      "1688/1688 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 187/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 188/200\n",
      "1688/1688 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 189/200\n",
      "1688/1688 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 190/200\n",
      "1688/1688 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 191/200\n",
      "1688/1688 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 192/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 193/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5083\n",
      "Epoch 194/200\n",
      "1688/1688 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 195/200\n",
      "1688/1688 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 196/200\n",
      "1688/1688 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 197/200\n",
      "1688/1688 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 198/200\n",
      "1688/1688 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 199/200\n",
      "1688/1688 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 200/200\n",
      "1688/1688 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.5083\n",
      "Epoch 1/200\n",
      "1689/1689 [==============================] - 1s 657us/step - loss: 0.6932 - acc: 0.4950\n",
      "Epoch 2/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.4902\n",
      "Epoch 3/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 4/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 5/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 6/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 8/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 9/200\n",
      "1689/1689 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 10/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 11/200\n",
      "1689/1689 [==============================] - 0s 291us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 12/200\n",
      "1689/1689 [==============================] - 0s 273us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 13/200\n",
      "1689/1689 [==============================] - 0s 285us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 14/200\n",
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 15/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 16/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 17/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 18/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.4890\n",
      "Epoch 19/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 20/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6933 - acc: 0.4950\n",
      "Epoch 21/200\n",
      "1689/1689 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 22/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 23/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 24/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5009\n",
      "Epoch 25/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 26/200\n",
      "1689/1689 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 27/200\n",
      "1689/1689 [==============================] - 1s 300us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 28/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 29/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 30/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 31/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.4855\n",
      "Epoch 32/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 33/200\n",
      "1689/1689 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 34/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 35/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 36/200\n",
      "1689/1689 [==============================] - 0s 285us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 37/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 38/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 39/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 40/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 41/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 42/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 43/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 44/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 45/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 46/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 47/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 48/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4914\n",
      "Epoch 49/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 50/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 51/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 52/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 53/200\n",
      "1689/1689 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 54/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.4962\n",
      "Epoch 55/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 56/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 57/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.4902\n",
      "Epoch 58/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 59/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 60/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 61/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 62/200\n",
      "1689/1689 [==============================] - 0s 288us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 63/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 64/200\n",
      "1689/1689 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.4926\n",
      "Epoch 65/200\n",
      "1689/1689 [==============================] - 0s 252us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 66/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 67/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5021\n",
      "Epoch 68/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 69/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 70/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 71/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 72/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6933 - acc: 0.4890\n",
      "Epoch 73/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 74/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 75/200\n",
      "1689/1689 [==============================] - 1s 312us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 76/200\n",
      "1689/1689 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 77/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 78/200\n",
      "1689/1689 [==============================] - 0s 287us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 79/200\n",
      "1689/1689 [==============================] - 0s 271us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 80/200\n",
      "1689/1689 [==============================] - 0s 282us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 81/200\n",
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 82/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 83/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 84/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 85/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 86/200\n",
      "1689/1689 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 87/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 89/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.4985\n",
      "Epoch 90/200\n",
      "1689/1689 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 91/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 92/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 93/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 94/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 95/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 96/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 97/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 98/200\n",
      "1689/1689 [==============================] - 1s 327us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 99/200\n",
      "1689/1689 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 100/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 101/200\n",
      "1689/1689 [==============================] - 0s 282us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 102/200\n",
      "1689/1689 [==============================] - 0s 255us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 103/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 104/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 105/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 106/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 107/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.4997\n",
      "Epoch 108/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 109/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 110/200\n",
      "1689/1689 [==============================] - 0s 208us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 111/200\n",
      "1689/1689 [==============================] - 0s 274us/step - loss: 0.6932 - acc: 0.4938\n",
      "Epoch 112/200\n",
      "1689/1689 [==============================] - 0s 254us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 113/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 114/200\n",
      "1689/1689 [==============================] - 0s 256us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 115/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 116/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 117/200\n",
      "1689/1689 [==============================] - 1s 297us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 118/200\n",
      "1689/1689 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 119/200\n",
      "1689/1689 [==============================] - 0s 280us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 120/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 121/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6933 - acc: 0.4902\n",
      "Epoch 122/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 123/200\n",
      "1689/1689 [==============================] - 0s 216us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 124/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 125/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 126/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 127/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 128/200\n",
      "1689/1689 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 129/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.4926\n",
      "Epoch 130/200\n",
      "1689/1689 [==============================] - 0s 273us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 131/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 132/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 133/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4879\n",
      "Epoch 134/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 135/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 136/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 137/200\n",
      "1689/1689 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 138/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 139/200\n",
      "1689/1689 [==============================] - 0s 279us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 140/200\n",
      "1689/1689 [==============================] - 0s 273us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 141/200\n",
      "1689/1689 [==============================] - 0s 278us/step - loss: 0.6932 - acc: 0.4950\n",
      "Epoch 142/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 143/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 144/200\n",
      "1689/1689 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 145/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 146/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 147/200\n",
      "1689/1689 [==============================] - 0s 274us/step - loss: 0.6933 - acc: 0.4962\n",
      "Epoch 148/200\n",
      "1689/1689 [==============================] - 0s 264us/step - loss: 0.6933 - acc: 0.4914\n",
      "Epoch 149/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 150/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 151/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 152/200\n",
      "1689/1689 [==============================] - 1s 304us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 153/200\n",
      "1689/1689 [==============================] - 0s 247us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 154/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 155/200\n",
      "1689/1689 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 156/200\n",
      "1689/1689 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.4879\n",
      "Epoch 157/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 158/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 159/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 160/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 161/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 162/200\n",
      "1689/1689 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 163/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4926\n",
      "Epoch 164/200\n",
      "1689/1689 [==============================] - 0s 251us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 165/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 166/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 167/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 169/200\n",
      "1689/1689 [==============================] - 0s 294us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 170/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 171/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 172/200\n",
      "1689/1689 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 173/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 174/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 175/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 176/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 177/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 178/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 179/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 180/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 181/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 182/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 183/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 184/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.4867\n",
      "Epoch 185/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 186/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 187/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 188/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.4938\n",
      "Epoch 189/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 190/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 191/200\n",
      "1689/1689 [==============================] - 0s 264us/step - loss: 0.6933 - acc: 0.4938\n",
      "Epoch 192/200\n",
      "1689/1689 [==============================] - 0s 279us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 193/200\n",
      "1689/1689 [==============================] - 1s 438us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 194/200\n",
      "1689/1689 [==============================] - 1s 325us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 195/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5044\n",
      "Epoch 196/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 197/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 198/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6933 - acc: 0.5044\n",
      "Epoch 199/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6933 - acc: 0.4938\n",
      "Epoch 200/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6934 - acc: 0.5044\n",
      "Epoch 1/200\n",
      "1689/1689 [==============================] - 1s 726us/step - loss: 0.6933 - acc: 0.4766\n",
      "Epoch 2/200\n",
      "1689/1689 [==============================] - 0s 280us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 3/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 4/200\n",
      "1689/1689 [==============================] - 0s 285us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 5/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.4967\n",
      "Epoch 6/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 7/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.4991\n",
      "Epoch 8/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 9/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 10/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 11/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6933 - acc: 0.4861\n",
      "Epoch 12/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 13/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 14/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 15/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4778\n",
      "Epoch 16/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 17/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4837\n",
      "Epoch 18/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 19/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 20/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 21/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 22/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 23/200\n",
      "1689/1689 [==============================] - 0s 217us/step - loss: 0.6933 - acc: 0.4825\n",
      "Epoch 24/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 25/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 26/200\n",
      "1689/1689 [==============================] - 0s 211us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 27/200\n",
      "1689/1689 [==============================] - 0s 217us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 28/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 29/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.4885\n",
      "Epoch 30/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 31/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 32/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 33/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 34/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 35/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 36/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 37/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 38/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 39/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 40/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 41/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 42/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 43/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.4849\n",
      "Epoch 44/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 45/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 46/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6933 - acc: 0.4956\n",
      "Epoch 47/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 48/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 50/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 51/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 52/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 53/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 54/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.4920\n",
      "Epoch 55/200\n",
      "1689/1689 [==============================] - 0s 249us/step - loss: 0.6933 - acc: 0.4861\n",
      "Epoch 56/200\n",
      "1689/1689 [==============================] - 0s 275us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 57/200\n",
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 58/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6933 - acc: 0.4790\n",
      "Epoch 59/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6934 - acc: 0.4849\n",
      "Epoch 60/200\n",
      "1689/1689 [==============================] - 1s 297us/step - loss: 0.6933 - acc: 0.4991\n",
      "Epoch 61/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4885\n",
      "Epoch 62/200\n",
      "1689/1689 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 63/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6933 - acc: 0.4932\n",
      "Epoch 64/200\n",
      "1689/1689 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 65/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 66/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 67/200\n",
      "1689/1689 [==============================] - 0s 285us/step - loss: 0.6933 - acc: 0.4896\n",
      "Epoch 68/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 69/200\n",
      "1689/1689 [==============================] - 0s 292us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 70/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 71/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 72/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6934 - acc: 0.5027\n",
      "Epoch 73/200\n",
      "1689/1689 [==============================] - 0s 216us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 74/200\n",
      "1689/1689 [==============================] - 0s 216us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 75/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5003\n",
      "Epoch 76/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.4944\n",
      "Epoch 77/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.4896\n",
      "Epoch 78/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 79/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 80/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 81/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 82/200\n",
      "1689/1689 [==============================] - 0s 215us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 83/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 84/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5003\n",
      "Epoch 85/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 86/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.4754\n",
      "Epoch 87/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 88/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 89/200\n",
      "1689/1689 [==============================] - 0s 214us/step - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 90/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 91/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 92/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 93/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 94/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 95/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.4790\n",
      "Epoch 96/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.4885\n",
      "Epoch 97/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 98/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6933 - acc: 0.4873\n",
      "Epoch 99/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 100/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 101/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.4766\n",
      "Epoch 102/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 103/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 104/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 105/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 106/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 107/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.4849\n",
      "Epoch 108/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 109/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 110/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6933 - acc: 0.4873\n",
      "Epoch 111/200\n",
      "1689/1689 [==============================] - 0s 279us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 112/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 113/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.4944\n",
      "Epoch 114/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 115/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 116/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 117/200\n",
      "1689/1689 [==============================] - 0s 258us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 118/200\n",
      "1689/1689 [==============================] - 0s 254us/step - loss: 0.6933 - acc: 0.4719\n",
      "Epoch 119/200\n",
      "1689/1689 [==============================] - 0s 275us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 120/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 121/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 122/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 123/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 124/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 125/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.4991\n",
      "Epoch 126/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 127/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4932\n",
      "Epoch 128/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 129/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.4861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 131/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 132/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 133/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6933 - acc: 0.4813\n",
      "Epoch 134/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 135/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 136/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 137/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.4813\n",
      "Epoch 138/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 139/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6933 - acc: 0.4861\n",
      "Epoch 140/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 141/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 142/200\n",
      "1689/1689 [==============================] - 0s 214us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 143/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 144/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 145/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6933 - acc: 0.4932\n",
      "Epoch 146/200\n",
      "1689/1689 [==============================] - 0s 257us/step - loss: 0.6933 - acc: 0.4932\n",
      "Epoch 147/200\n",
      "1689/1689 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 148/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 149/200\n",
      "1689/1689 [==============================] - 0s 281us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 150/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 151/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 152/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 153/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 154/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 155/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 156/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 157/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 158/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 159/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.4944\n",
      "Epoch 160/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.4908\n",
      "Epoch 161/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 162/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.4944\n",
      "Epoch 163/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 164/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 165/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 166/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 167/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 168/200\n",
      "1689/1689 [==============================] - 0s 249us/step - loss: 0.6933 - acc: 0.4896\n",
      "Epoch 169/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.4861\n",
      "Epoch 170/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 171/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6933 - acc: 0.4956\n",
      "Epoch 172/200\n",
      "1689/1689 [==============================] - 0s 251us/step - loss: 0.6933 - acc: 0.4873\n",
      "Epoch 173/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 174/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 175/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 176/200\n",
      "1689/1689 [==============================] - 0s 249us/step - loss: 0.6933 - acc: 0.4885\n",
      "Epoch 177/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 178/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 179/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 180/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 181/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 182/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.4766\n",
      "Epoch 183/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 184/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 185/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 186/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 187/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 188/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.4944\n",
      "Epoch 189/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 190/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 191/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 192/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 193/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 194/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 195/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6933 - acc: 0.4885\n",
      "Epoch 196/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6933 - acc: 0.4944\n",
      "Epoch 197/200\n",
      "1689/1689 [==============================] - 1s 302us/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 198/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 199/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 200/200\n",
      "1689/1689 [==============================] - 0s 279us/step - loss: 0.6933 - acc: 0.5027\n",
      "Epoch 1/200\n",
      "1689/1689 [==============================] - 1s 702us/step - loss: 0.6932 - acc: 0.4991\n",
      "Epoch 2/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 3/200\n",
      "1689/1689 [==============================] - 0s 257us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 4/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 5/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 6/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 7/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 8/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 9/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 11/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 12/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 13/200\n",
      "1689/1689 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 14/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 15/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 16/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 17/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 18/200\n",
      "1689/1689 [==============================] - 0s 287us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 19/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 20/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 21/200\n",
      "1689/1689 [==============================] - 0s 287us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 22/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 23/200\n",
      "1689/1689 [==============================] - 0s 289us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 24/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 25/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 26/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 27/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 28/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 29/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 30/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 31/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 32/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 33/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 34/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 35/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 36/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 37/200\n",
      "1689/1689 [==============================] - 0s 218us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 38/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 39/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 40/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 41/200\n",
      "1689/1689 [==============================] - 1s 304us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 42/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 43/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 44/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 45/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 46/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 47/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 48/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 49/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 50/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 51/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 52/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 53/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 54/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 55/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 56/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 57/200\n",
      "1689/1689 [==============================] - 0s 270us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 58/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 59/200\n",
      "1689/1689 [==============================] - 0s 280us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 60/200\n",
      "1689/1689 [==============================] - 0s 283us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 61/200\n",
      "1689/1689 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 62/200\n",
      "1689/1689 [==============================] - 0s 253us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 63/200\n",
      "1689/1689 [==============================] - 0s 253us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 64/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 65/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 66/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 67/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 68/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 69/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 70/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 71/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 72/200\n",
      "1689/1689 [==============================] - 0s 247us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 73/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 74/200\n",
      "1689/1689 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 75/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 76/200\n",
      "1689/1689 [==============================] - 0s 281us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 77/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 78/200\n",
      "1689/1689 [==============================] - 0s 262us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 79/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 80/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 81/200\n",
      "1689/1689 [==============================] - 0s 263us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 82/200\n",
      "1689/1689 [==============================] - 0s 281us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 83/200\n",
      "1689/1689 [==============================] - 0s 257us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 84/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 85/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 86/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 87/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 88/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 89/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 90/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 92/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 93/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 94/200\n",
      "1689/1689 [==============================] - 0s 278us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 95/200\n",
      "1689/1689 [==============================] - 0s 291us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 96/200\n",
      "1689/1689 [==============================] - 1s 300us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 97/200\n",
      "1689/1689 [==============================] - 0s 255us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 98/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 99/200\n",
      "1689/1689 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 100/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 101/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 102/200\n",
      "1689/1689 [==============================] - 0s 265us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 103/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 104/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 105/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 106/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 107/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 108/200\n",
      "1689/1689 [==============================] - 0s 258us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 109/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 110/200\n",
      "1689/1689 [==============================] - 0s 252us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 111/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 112/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 113/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 114/200\n",
      "1689/1689 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 115/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 116/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 117/200\n",
      "1689/1689 [==============================] - 1s 350us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 118/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 119/200\n",
      "1689/1689 [==============================] - 1s 305us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 120/200\n",
      "1689/1689 [==============================] - 0s 271us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 121/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 122/200\n",
      "1689/1689 [==============================] - 0s 275us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 123/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 124/200\n",
      "1689/1689 [==============================] - 0s 293us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 125/200\n",
      "1689/1689 [==============================] - 1s 309us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 126/200\n",
      "1689/1689 [==============================] - 1s 307us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 127/200\n",
      "1689/1689 [==============================] - 1s 302us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 128/200\n",
      "1689/1689 [==============================] - 1s 321us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 129/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 130/200\n",
      "1689/1689 [==============================] - 0s 291us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 131/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 132/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 133/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6930 - acc: 0.5086\n",
      "Epoch 134/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 135/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 136/200\n",
      "1689/1689 [==============================] - 0s 295us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 137/200\n",
      "1689/1689 [==============================] - 1s 333us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 138/200\n",
      "1689/1689 [==============================] - 1s 330us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 139/200\n",
      "1689/1689 [==============================] - 1s 330us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 140/200\n",
      "1689/1689 [==============================] - 1s 307us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 141/200\n",
      "1689/1689 [==============================] - 0s 263us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 142/200\n",
      "1689/1689 [==============================] - 0s 290us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 143/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 144/200\n",
      "1689/1689 [==============================] - 0s 282us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 145/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 146/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 147/200\n",
      "1689/1689 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 148/200\n",
      "1689/1689 [==============================] - 1s 309us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 149/200\n",
      "1689/1689 [==============================] - 0s 262us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 150/200\n",
      "1689/1689 [==============================] - 0s 264us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 151/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 152/200\n",
      "1689/1689 [==============================] - 0s 259us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 153/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 154/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 155/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 156/200\n",
      "1689/1689 [==============================] - 0s 251us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 157/200\n",
      "1689/1689 [==============================] - 0s 270us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 158/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 159/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 160/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 161/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 162/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 163/200\n",
      "1689/1689 [==============================] - 1s 333us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 164/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 165/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 166/200\n",
      "1689/1689 [==============================] - 1s 304us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 167/200\n",
      "1689/1689 [==============================] - 1s 307us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 168/200\n",
      "1689/1689 [==============================] - 0s 294us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 169/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 170/200\n",
      "1689/1689 [==============================] - 0s 258us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 172/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 173/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 174/200\n",
      "1689/1689 [==============================] - 1s 322us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 175/200\n",
      "1689/1689 [==============================] - 0s 254us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 176/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 177/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 178/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 179/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 180/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 181/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 182/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 183/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 184/200\n",
      "1689/1689 [==============================] - 0s 217us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 185/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 186/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 187/200\n",
      "1689/1689 [==============================] - 0s 216us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 188/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 189/200\n",
      "1689/1689 [==============================] - 0s 213us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 190/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 191/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 192/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 193/200\n",
      "1689/1689 [==============================] - 0s 287us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 194/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 195/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 196/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 197/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 198/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 199/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5086\n",
      "Epoch 200/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6931 - acc: 0.5086\n",
      "Epoch 1/200\n",
      "1689/1689 [==============================] - 1s 725us/step - loss: 0.6933 - acc: 0.4956\n",
      "Epoch 2/200\n",
      "1689/1689 [==============================] - 1s 310us/step - loss: 0.6932 - acc: 0.4920\n",
      "Epoch 3/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.4896\n",
      "Epoch 4/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 5/200\n",
      "1689/1689 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 6/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 7/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 8/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 9/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5015\n",
      "Epoch 10/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 11/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 12/200\n",
      "1689/1689 [==============================] - 0s 219us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 13/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5027\n",
      "Epoch 14/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 15/200\n",
      "1689/1689 [==============================] - 0s 271us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 16/200\n",
      "1689/1689 [==============================] - 1s 368us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 17/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6933 - acc: 0.4944\n",
      "Epoch 18/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 19/200\n",
      "1689/1689 [==============================] - 1s 313us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 20/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 21/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 22/200\n",
      "1689/1689 [==============================] - 0s 247us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 23/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 24/200\n",
      "1689/1689 [==============================] - 1s 377us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 25/200\n",
      "1689/1689 [==============================] - 1s 302us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 26/200\n",
      "1689/1689 [==============================] - 0s 280us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 27/200\n",
      "1689/1689 [==============================] - 0s 274us/step - loss: 0.6933 - acc: 0.4967\n",
      "Epoch 28/200\n",
      "1689/1689 [==============================] - 0s 259us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 29/200\n",
      "1689/1689 [==============================] - 1s 350us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 30/200\n",
      "1689/1689 [==============================] - 1s 419us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 31/200\n",
      "1689/1689 [==============================] - 1s 409us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 32/200\n",
      "1689/1689 [==============================] - 1s 360us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 33/200\n",
      "1689/1689 [==============================] - 1s 585us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 34/200\n",
      "1689/1689 [==============================] - 1s 402us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 35/200\n",
      "1689/1689 [==============================] - 1s 515us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 36/200\n",
      "1689/1689 [==============================] - 1s 405us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 37/200\n",
      "1689/1689 [==============================] - 1s 441us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 38/200\n",
      "1689/1689 [==============================] - 1s 354us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 39/200\n",
      "1689/1689 [==============================] - 0s 279us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 40/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 41/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.4920\n",
      "Epoch 42/200\n",
      "1689/1689 [==============================] - 1s 356us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 43/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 44/200\n",
      "1689/1689 [==============================] - 0s 258us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 45/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 46/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 47/200\n",
      "1689/1689 [==============================] - 0s 251us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 48/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 49/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6933 - acc: 0.5015\n",
      "Epoch 50/200\n",
      "1689/1689 [==============================] - 0s 272us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 51/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 52/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 53/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 54/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 55/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 56/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.4932\n",
      "Epoch 57/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 58/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 59/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 60/200\n",
      "1689/1689 [==============================] - 1s 297us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 61/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 62/200\n",
      "1689/1689 [==============================] - 0s 277us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 63/200\n",
      "1689/1689 [==============================] - 1s 323us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 64/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 65/200\n",
      "1689/1689 [==============================] - 0s 252us/step - loss: 0.6932 - acc: 0.4920\n",
      "Epoch 66/200\n",
      "1689/1689 [==============================] - 0s 276us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 67/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 68/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 69/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 70/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 71/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 72/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 73/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 74/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 75/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 76/200\n",
      "1689/1689 [==============================] - 0s 225us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 77/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 78/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 79/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 80/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 81/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 82/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 83/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6933 - acc: 0.4849\n",
      "Epoch 84/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 85/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 86/200\n",
      "1689/1689 [==============================] - 1s 313us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 87/200\n",
      "1689/1689 [==============================] - 0s 243us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 88/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.4837\n",
      "Epoch 89/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6933 - acc: 0.4920\n",
      "Epoch 90/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 91/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 92/200\n",
      "1689/1689 [==============================] - 0s 250us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 93/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 94/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 95/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 96/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 97/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 98/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 99/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 100/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 101/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 102/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 103/200\n",
      "1689/1689 [==============================] - 1s 361us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 104/200\n",
      "1689/1689 [==============================] - 0s 269us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 105/200\n",
      "1689/1689 [==============================] - 1s 326us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 106/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 107/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 108/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.4979\n",
      "Epoch 109/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 110/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 111/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 112/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 113/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 114/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 115/200\n",
      "1689/1689 [==============================] - 0s 268us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 116/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 117/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 118/200\n",
      "1689/1689 [==============================] - 0s 289us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 119/200\n",
      "1689/1689 [==============================] - 1s 318us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 120/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 121/200\n",
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 122/200\n",
      "1689/1689 [==============================] - 0s 261us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 123/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 124/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 125/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 126/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.4932\n",
      "Epoch 127/200\n",
      "1689/1689 [==============================] - 0s 267us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 128/200\n",
      "1689/1689 [==============================] - 1s 325us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 129/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 130/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 131/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 132/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689/1689 [==============================] - 0s 288us/step - loss: 0.6932 - acc: 0.4956\n",
      "Epoch 133/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 134/200\n",
      "1689/1689 [==============================] - 0s 271us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 135/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 136/200\n",
      "1689/1689 [==============================] - 0s 289us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 137/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 138/200\n",
      "1689/1689 [==============================] - 0s 230us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 139/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 140/200\n",
      "1689/1689 [==============================] - 0s 284us/step - loss: 0.6931 - acc: 0.5050\n",
      "Epoch 141/200\n",
      "1689/1689 [==============================] - 1s 307us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 142/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 143/200\n",
      "1689/1689 [==============================] - 1s 305us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 144/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 145/200\n",
      "1689/1689 [==============================] - 0s 248us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 146/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 147/200\n",
      "1689/1689 [==============================] - 0s 239us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 148/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 149/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 150/200\n",
      "1689/1689 [==============================] - 0s 244us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 151/200\n",
      "1689/1689 [==============================] - 0s 227us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 152/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 153/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 154/200\n",
      "1689/1689 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 155/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 156/200\n",
      "1689/1689 [==============================] - 0s 224us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 157/200\n",
      "1689/1689 [==============================] - 0s 220us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 158/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 159/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 160/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 161/200\n",
      "1689/1689 [==============================] - 0s 241us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 162/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 163/200\n",
      "1689/1689 [==============================] - 0s 223us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 164/200\n",
      "1689/1689 [==============================] - 0s 238us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 165/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 166/200\n",
      "1689/1689 [==============================] - 0s 255us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 167/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 168/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 169/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 170/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 171/200\n",
      "1689/1689 [==============================] - 0s 228us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 172/200\n",
      "1689/1689 [==============================] - 0s 265us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 173/200\n",
      "1689/1689 [==============================] - 1s 297us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 174/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 175/200\n",
      "1689/1689 [==============================] - 0s 260us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 176/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 177/200\n",
      "1689/1689 [==============================] - 0s 242us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 178/200\n",
      "1689/1689 [==============================] - 0s 291us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 179/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 180/200\n",
      "1689/1689 [==============================] - 0s 266us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 181/200\n",
      "1689/1689 [==============================] - 0s 246us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 182/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 183/200\n",
      "1689/1689 [==============================] - 0s 236us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 184/200\n",
      "1689/1689 [==============================] - 0s 229us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 185/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 186/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 187/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 188/200\n",
      "1689/1689 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 189/200\n",
      "1689/1689 [==============================] - 0s 234us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 190/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.4967\n",
      "Epoch 191/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 192/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.4896\n",
      "Epoch 193/200\n",
      "1689/1689 [==============================] - 0s 237us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 194/200\n",
      "1689/1689 [==============================] - 0s 221us/step - loss: 0.6933 - acc: 0.4956\n",
      "Epoch 195/200\n",
      "1689/1689 [==============================] - 0s 235us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 196/200\n",
      "1689/1689 [==============================] - 0s 231us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 197/200\n",
      "1689/1689 [==============================] - 0s 240us/step - loss: 0.6933 - acc: 0.5050\n",
      "Epoch 198/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 199/200\n",
      "1689/1689 [==============================] - 0s 232us/step - loss: 0.6932 - acc: 0.5050\n",
      "Epoch 200/200\n",
      "1689/1689 [==============================] - 0s 233us/step - loss: 0.6932 - acc: 0.5050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70212766, 0.4893617 , 0.65425532, 0.5106383 , 0.66489362,\n",
       "       0.4787234 , 0.51336898, 0.52941176, 0.47593583, 0.50802139])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus = cross_val_score(estimator=classifier, X=X_train,\n",
    "                        y=y_train, cv=10, n_jobs=-2, scoring='accuracy')\n",
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:02:09.616879Z",
     "start_time": "2018-11-01T03:02:09.580513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5526737967914438"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_mean = accus.mean()\n",
    "accu_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:02:11.524193Z",
     "start_time": "2018-11-01T03:02:11.498485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08152371401080122"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accu_var = accus.std()\n",
    "accu_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:02:26.103511Z",
     "start_time": "2018-11-01T03:02:26.077809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70212766, 0.4893617 , 0.65425532, 0.5106383 , 0.66489362,\n",
       "       0.4787234 , 0.51336898, 0.52941176, 0.47593583, 0.50802139])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:37:05.729652Z",
     "start_time": "2018-11-01T03:37:05.691484Z"
    }
   },
   "outputs": [],
   "source": [
    "def dropout_classifier(optimizer, metrics):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=5, kernel_initializer='uniform',\n",
    "                         activation='relu', input_dim=5))\n",
    "    classifier.add(Dropout(rate=0.12))\n",
    "    classifier.add(\n",
    "        Dense(units=40, kernel_initializer='uniform', activation='softsign'))\n",
    "    classifier.add(Dropout(rate=0.08))\n",
    "    classifier.add(\n",
    "        Dense(units=8, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dropout(rate=0.04))\n",
    "    classifier.add(\n",
    "        Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    classifier.compile(\n",
    "        optimizer=optimizer, loss='binary_crossentropy', metrics=[metrics])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:37:06.613594Z",
     "start_time": "2018-11-01T03:37:06.590415Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn=dropout_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:37:07.601633Z",
     "start_time": "2018-11-01T03:37:07.578951Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {'batch_size': [4, 8, 12, 16, 32, 64, 128],\n",
    "              'nb_epoch': [50, 100, 250, 500, 1000],\n",
    "              'optimizer': ['Nadam', 'Adadelta', 'Adamax', 'SGD', 'Adam', 'RMSprop'],\n",
    "              'metrics': ['accuracy', 'mean_absolute_error', 'squared_hinge', 'binary_accuracy', 'mean_absolute_percentage_error']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:37:09.121786Z",
     "start_time": "2018-11-01T03:37:09.097939Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(classifier, parameters,\n",
    "                           scoring='accuracy', cv=10, n_jobs=-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T03:37:47.966386Z",
     "start_time": "2018-11-01T03:37:10.659097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 1ms/step - loss: 0.6351 - acc: 0.6149\n",
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6313 - acc: 0.6481\n",
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6933 - acc: 0.4953\n",
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6152 - acc: 0.6475\n",
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6195 - acc: 0.6333\n",
      "Epoch 1/1\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6212 - acc: 0.6493\n",
      "Epoch 1/1\n",
      "1689/1689 [==============================] - 3s 2ms/step - loss: 0.6246 - acc: 0.6442\n",
      "Epoch 1/1\n",
      "1689/1689 [==============================] - 3s 2ms/step - loss: 0.6327 - acc: 0.6347\n",
      "Epoch 1/1\n",
      "1048/1689 [=================>............] - ETA: 1s - loss: 0.6422 - acc: 0.6231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-49331c6d52db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     95\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \"\"\"\n\u001b[1;32m   3335\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3336\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3356\u001b[0m         \u001b[0mkth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3357\u001b[0m     \u001b[0;31m# Check if the array contains any nan's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3358\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3359\u001b[0m         \u001b[0mkth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m--> 713\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubclass_\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \"\"\"\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T04:40:48.737066Z",
     "start_time": "2018-10-20T04:40:48.716317Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T04:40:48.766281Z",
     "start_time": "2018-10-20T04:40:48.739293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_accu = grid_search.best_score_\n",
    "best_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T04:40:51.334697Z",
     "start_time": "2018-10-20T04:40:48.768478Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T04:40:51.359274Z",
     "start_time": "2018-10-20T04:40:51.336760Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T04:41:16.175429Z",
     "start_time": "2018-10-20T04:41:16.148787Z"
    }
   },
   "outputs": [],
   "source": [
    "(56+38)/(67+57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
